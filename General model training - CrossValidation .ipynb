{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import os\n",
    "# from pandas._testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "\n",
    "saved_model_dir = \"saved_model/corss_val/general_model/hp_seq_len/\"\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "saving_dir = \"cross_validation/general_model/hp_seq_len/\"\n",
    "if not os.path.exists(saving_dir):\n",
    "    os.makedirs(saving_dir)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_SIZE = 64\n",
    "TRAIN_EPOCHS = 300\n",
    "\n",
    "print_iter = 50\n",
    "TRAIN_BATCHES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation/general_model/hp_seq_len/2\n",
      "cross_validation/general_model/hp_seq_len/3\n",
      "cross_validation/general_model/hp_seq_len/4\n",
      "cross_validation/general_model/hp_seq_len/5\n",
      "cross_validation/general_model/hp_seq_len/6\n",
      "cross_validation/general_model/hp_seq_len/7\n",
      "cross_validation/general_model/hp_seq_len/8\n",
      "cross_validation/general_model/hp_seq_len/9\n",
      "cross_validation/general_model/hp_seq_len/10\n",
      "cross_validation/general_model/hp_seq_len/11\n",
      "cross_validation/general_model/hp_seq_len/12\n"
     ]
    }
   ],
   "source": [
    "seq_lengths_to_evaluate = [2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "saving_dirs = []\n",
    "for s in seq_lengths_to_evaluate:\n",
    "    cur_saving_dir = os.path.join(saving_dir, str(s))\n",
    "    print(cur_saving_dir)\n",
    "    saving_dirs.append(cur_saving_dir)\n",
    "    if not os.path.exists(cur_saving_dir):\n",
    "        os.makedirs(cur_saving_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cross_validation/general_model/hp_seq_len/2',\n",
       " 'cross_validation/general_model/hp_seq_len/3',\n",
       " 'cross_validation/general_model/hp_seq_len/4',\n",
       " 'cross_validation/general_model/hp_seq_len/5',\n",
       " 'cross_validation/general_model/hp_seq_len/6',\n",
       " 'cross_validation/general_model/hp_seq_len/7',\n",
       " 'cross_validation/general_model/hp_seq_len/8',\n",
       " 'cross_validation/general_model/hp_seq_len/9',\n",
       " 'cross_validation/general_model/hp_seq_len/10',\n",
       " 'cross_validation/general_model/hp_seq_len/11',\n",
       " 'cross_validation/general_model/hp_seq_len/12']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results from py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train results for seq=2 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/2\\\\fold0/----average train accuracy:0.69743776---- highest train accuracy:0.70319057',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold1/----average train accuracy:0.6968444---- highest train accuracy:0.7018483',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold2/----average train accuracy:0.69579965---- highest train accuracy:0.7007949',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold3/----average train accuracy:0.69462276---- highest train accuracy:0.69909346',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold4/----average train accuracy:0.7064296---- highest train accuracy:0.7098457']\n",
    "\n",
    "\n",
    "test_seq_2=['saved_model/corss_val/general_model/hp_seq_len/2\\\\fold0/----average test accuracy:0.70266396---- highest test accuracy:0.7265625',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold1/----average test accuracy:0.70789534---- highest test accuracy:0.7246094',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold2/----average test accuracy:0.70961267---- highest test accuracy:0.71875',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold3/----average test accuracy:0.7126808---- highest test accuracy:0.7265625',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/2\\\\fold4/----average test accuracy:0.6702833---- highest test accuracy:0.72527474']\n",
    "\n",
    "# Train results for seq=3 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/3\\\\fold0/----average train accuracy:0.7186975---- highest train accuracy:0.7270199',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold1/----average train accuracy:0.71829903---- highest train accuracy:0.7276714',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold2/----average train accuracy:0.7188148---- highest train accuracy:0.726138',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold3/----average train accuracy:0.71595603---- highest train accuracy:0.72585255',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold4/----average train accuracy:0.72719127---- highest train accuracy:0.7359394']\n",
    "\n",
    "\n",
    "test_seq_3=['saved_model/corss_val/general_model/hp_seq_len/3\\\\fold0/----average test accuracy:0.7215673---- highest test accuracy:0.7319336',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold1/----average test accuracy:0.72080886---- highest test accuracy:0.7441406',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold2/----average test accuracy:0.72347707---- highest test accuracy:0.73828125',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold3/----average test accuracy:0.72951066---- highest test accuracy:0.7524414',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/3\\\\fold4/----average test accuracy:0.685962---- highest test accuracy:0.7026367']\n",
    "\n",
    "\n",
    "# Train results for seq=4 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/4\\\\fold0/----average train accuracy:0.7343996---- highest train accuracy:0.7466801',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold1/----average train accuracy:0.73457426---- highest train accuracy:0.74807006',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold2/----average train accuracy:0.7334012---- highest train accuracy:0.7467825',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold3/----average train accuracy:0.73097575---- highest train accuracy:0.7449482',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold4/----average train accuracy:0.74191767---- highest train accuracy:0.7547348']\n",
    "\n",
    "\n",
    "# test_seq_4=['saved_model/corss_val/general_model/hp_seq_len/4\\\\fold0/----average test accuracy:0.7284037---- highest test accuracy:0.7495117',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold1/----average test accuracy:0.7292933---- highest test accuracy:0.7504883',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold2/----average test accuracy:0.72721666---- highest test accuracy:0.7529297',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold3/----average test accuracy:0.7387695---- highest test accuracy:0.7602539',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/4\\\\fold4/----average test accuracy:0.69093317---- highest test accuracy:0.70751953']\n",
    "\n",
    "# older CV model for seq=4\n",
    "test_seq_4=['saved_model/corss_val/general_model/fold0/----average test accuracy:0.72938126---- highest test accuracy:0.7518657',\n",
    " 'saved_model/corss_val/general_model/fold1/----average test accuracy:0.72858906---- highest test accuracy:0.75',\n",
    " 'saved_model/corss_val/general_model/fold2/----average test accuracy:0.72914827---- highest test accuracy:0.75439453',\n",
    " 'saved_model/corss_val/general_model/fold3/----average test accuracy:0.7381668---- highest test accuracy:0.74560547',\n",
    " 'saved_model/corss_val/general_model/fold4/----average test accuracy:0.6931991---- highest test accuracy:0.7073892']\n",
    "\n",
    "# Train results for seq=5 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/5\\\\fold0/----average train accuracy:0.74116105---- highest train accuracy:0.7572236',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold1/----average train accuracy:0.7419613---- highest train accuracy:0.7601643', \n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold2/----average train accuracy:0.7409074---- highest train accuracy:0.75949925',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold3/----average train accuracy:0.73863983---- highest train accuracy:0.75660086',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold4/----average train accuracy:0.7514091---- highest train accuracy:0.76927805']\n",
    "\n",
    "\n",
    "test_seq_5=['saved_model/corss_val/general_model/hp_seq_len/5\\\\fold0/----average test accuracy:0.73164874---- highest test accuracy:0.75341797',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold1/----average test accuracy:0.7266043---- highest test accuracy:0.73779297',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold2/----average test accuracy:0.7294124---- highest test accuracy:0.7475586', \n",
    " 'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold3/----average test accuracy:0.73751885---- highest test accuracy:0.7519531',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/5\\\\fold4/----average test accuracy:0.69434---- highest test accuracy:0.7138672']\n",
    "\n",
    "\n",
    "# Train results for seq=6 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/6\\\\fold0/----average train accuracy:0.75037974---- highest train accuracy:0.76979005',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold1/----average train accuracy:0.75209045---- highest train accuracy:0.7719154', 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold2/----average train accuracy:0.7478511---- highest train accuracy:0.7678787', 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold3/----average train accuracy:0.74656516---- highest train accuracy:0.76814365', 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold4/----average train accuracy:0.757038---- highest train accuracy:0.77707523']\n",
    "\n",
    "\n",
    "test_seq_6 = ['saved_model/corss_val/general_model/hp_seq_len/6\\\\fold0/----average test accuracy:0.7317986---- highest test accuracy:0.7470703',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold1/----average test accuracy:0.728501---- highest test accuracy:0.7504883',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold2/----average test accuracy:0.7357544---- highest test accuracy:0.7741935',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold3/----average test accuracy:0.7461369---- highest test accuracy:0.75634766',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/6\\\\fold4/----average test accuracy:0.69994736---- highest test accuracy:0.72021484']\n",
    "\n",
    "\n",
    "# Train results for seq=7 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/7\\\\fold0/----average train accuracy:0.7522943---- highest train accuracy:0.7737942',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold1/----average train accuracy:0.75565237---- highest train accuracy:0.7769185', \n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold2/----average train accuracy:0.75333977---- highest train accuracy:0.7765465',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold3/----average train accuracy:0.75095135---- highest train accuracy:0.7730789',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold4/----average train accuracy:0.7621781---- highest train accuracy:0.783765']\n",
    "\n",
    "\n",
    "test_seq_7 =['saved_model/corss_val/general_model/hp_seq_len/7\\\\fold0/----average test accuracy:0.7358662---- highest test accuracy:0.74902344',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold1/----average test accuracy:0.72893196---- highest test accuracy:0.74365234',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold2/----average test accuracy:0.7350679---- highest test accuracy:0.75341797',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold3/----average test accuracy:0.7492309---- highest test accuracy:0.76123047', \n",
    " 'saved_model/corss_val/general_model/hp_seq_len/7\\\\fold4/----average test accuracy:0.6973817---- highest test accuracy:0.71728516']\n",
    "\n",
    "\n",
    "# Train results for seq=8 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/8\\\\fold0/----average train accuracy:0.75805044---- highest train accuracy:0.77919793', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold1/----average train accuracy:0.75813943---- highest train accuracy:0.78034276', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold2/----average train accuracy:0.75631887---- highest train accuracy:0.7791558', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold3/----average train accuracy:0.75399435---- highest train accuracy:0.77680844', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold4/----average train accuracy:0.76602054---- highest train accuracy:0.78694063']\n",
    "\n",
    "\n",
    "test_seq_8=['saved_model/corss_val/general_model/hp_seq_len/8\\\\fold0/----average test accuracy:0.738746---- highest test accuracy:0.75097656', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold1/----average test accuracy:0.73174924---- highest test accuracy:0.74609375', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold2/----average test accuracy:0.7376924---- highest test accuracy:0.7647059', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold3/----average test accuracy:0.75172704---- highest test accuracy:0.76953125', 'saved_model/corss_val/general_model/hp_seq_len/8\\\\fold4/----average test accuracy:0.7006884---- highest test accuracy:0.71484375']\n",
    "\n",
    "\n",
    "# Train results for seq=9 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/9\\\\fold0/----average train accuracy:0.76169103---- highest train accuracy:0.7840254',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold1/----average train accuracy:0.7538542---- highest train accuracy:0.7769306',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold2/----average train accuracy:0.75991976---- highest train accuracy:0.7841459',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold3/----average train accuracy:0.7540679---- highest train accuracy:0.7770223', \n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold4/----average train accuracy:0.76865643---- highest train accuracy:0.7912821']\n",
    "\n",
    "\n",
    "test_seq_9=['saved_model/corss_val/general_model/hp_seq_len/9\\\\fold0/----average test accuracy:0.73685265---- highest test accuracy:0.75490195',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold1/----average test accuracy:0.7458005---- highest test accuracy:0.8518519', \n",
    " 'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold2/----average test accuracy:0.7371143---- highest test accuracy:0.7470703', \n",
    " 'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold3/----average test accuracy:0.74993384---- highest test accuracy:0.76953125',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/9\\\\fold4/----average test accuracy:0.7048274---- highest test accuracy:0.73209304']\n",
    "\n",
    "\n",
    "# Train results for seq=10 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/10\\\\fold0/----average train accuracy:0.7596463---- highest train accuracy:0.7809559',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold1/----average train accuracy:0.7633804---- highest train accuracy:0.7860405',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold2/----average train accuracy:0.75945324---- highest train accuracy:0.77971345',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold3/----average train accuracy:0.75683284---- highest train accuracy:0.78232044',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold4/----average train accuracy:0.76879555---- highest train accuracy:0.79256886']\n",
    "\n",
    "\n",
    "\n",
    "test_seq_10=['saved_model/corss_val/general_model/hp_seq_len/10\\\\fold0/----average test accuracy:0.7379746---- highest test accuracy:0.7583008',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold1/----average test accuracy:0.7361965---- highest test accuracy:0.75',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold2/----average test accuracy:0.7373353---- highest test accuracy:0.76171875',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold3/----average test accuracy:0.7539257---- highest test accuracy:0.7663657',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/10\\\\fold4/----average test accuracy:0.71008486---- highest test accuracy:0.729638']\n",
    "\n",
    "\n",
    "# Train results for seq=11 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/11\\\\fold0/----average train accuracy:0.7628429---- highest train accuracy:0.7867328',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold1/----average train accuracy:0.7640018---- highest train accuracy:0.7850241',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold2/----average train accuracy:0.7617712---- highest train accuracy:0.7829552',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold3/----average train accuracy:0.76002616---- highest train accuracy:0.7833906',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold4/----average train accuracy:0.770157---- highest train accuracy:0.7919311']\n",
    "\n",
    "\n",
    "test_seq_11=['saved_model/corss_val/general_model/hp_seq_len/11\\\\fold0/----average test accuracy:0.73625046---- highest test accuracy:0.7578125',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold1/----average test accuracy:0.73046845---- highest test accuracy:0.7573242',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold2/----average test accuracy:0.73876315---- highest test accuracy:0.7558594',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold3/----average test accuracy:0.7498242---- highest test accuracy:0.76220703',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/11\\\\fold4/----average test accuracy:0.7043658---- highest test accuracy:0.72021484']\n",
    "\n",
    "# Train results for seq=12 for all folds:\n",
    "# ['saved_model/corss_val/general_model/hp_seq_len/12\\\\fold0/----average train accuracy:0.7640528---- highest train accuracy:0.788933',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold1/----average train accuracy:0.76576406---- highest train accuracy:0.7905345',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold2/----average train accuracy:0.76543844---- highest train accuracy:0.790254',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold3/----average train accuracy:0.75844866---- highest train accuracy:0.78364414',\n",
    "#  'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold4/----average train accuracy:0.76989377---- highest train accuracy:0.79227644']\n",
    "\n",
    "test_seq_12 = ['saved_model/corss_val/general_model/hp_seq_len/12\\\\fold0/----average test accuracy:0.73803675---- highest test accuracy:0.7636719',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold1/----average test accuracy:0.7320703---- highest test accuracy:0.74853516',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold2/----average test accuracy:0.73679644---- highest test accuracy:0.7519531',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold3/----average test accuracy:0.7538846---- highest test accuracy:0.76660156',\n",
    " 'saved_model/corss_val/general_model/hp_seq_len/12\\\\fold4/----average test accuracy:0.7113206---- highest test accuracy:0.7549801']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoying_str_to_float(one_fold_res_str):\n",
    "    tmp = one_fold_res_str[one_fold_res_str.find(\"average test accuracy:\"):]\n",
    "    tmp = tmp[:tmp.find(\"-\")]\n",
    "    res = float(tmp[tmp.find(\":\")+1:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_mean(all_folds_res):\n",
    "    test_res = []\n",
    "    for fold_res in all_folds_res:\n",
    "        test_res.append(annoying_str_to_float(fold_res))\n",
    "    return np.mean(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = [test_seq_2,test_seq_3,test_seq_4,test_seq_5,test_seq_6,test_seq_7,test_seq_8,test_seq_9,test_seq_10,test_seq_11,test_seq_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for seq in all_seqs:\n",
    "    means.append(get_seq_mean(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7006272139999999,\n",
       " 0.716265178,\n",
       " 0.723696898,\n",
       " 0.7239048579999999,\n",
       " 0.7284276519999999,\n",
       " 0.729295732,\n",
       " 0.7321206160000001,\n",
       " 0.7349057379999999,\n",
       " 0.7351033920000001,\n",
       " 0.731934412,\n",
       " 0.7344217380000001]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.7006272139999999,\n",
       " 3: 0.716265178,\n",
       " 4: 0.723696898,\n",
       " 5: 0.7239048579999999,\n",
       " 6: 0.7284276519999999,\n",
       " 7: 0.729295732,\n",
       " 8: 0.7321206160000001,\n",
       " 9: 0.7349057379999999,\n",
       " 10: 0.7351033920000001,\n",
       " 11: 0.731934412,\n",
       " 12: 0.7344217380000001}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:j for i,j in zip(seq_lengths_to_evaluate, means)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths_to_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,  6. ,  6.5,  7. ,\n",
       "        7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5, 11. , 11.5])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,12,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figsize=(20,12)\n",
    "plt.plot(seq_lengths_to_evaluate, np.array(means))\n",
    "plt.yticks(np.arange(0.65, 0.8, step=0.05))\n",
    "plt.xlabel(\"seq length\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model/corss_val/general_model/hp_seq_len/2\n",
      "saved_model/corss_val/general_model/hp_seq_len/3\n",
      "saved_model/corss_val/general_model/hp_seq_len/4\n",
      "saved_model/corss_val/general_model/hp_seq_len/5\n",
      "saved_model/corss_val/general_model/hp_seq_len/6\n",
      "saved_model/corss_val/general_model/hp_seq_len/7\n",
      "saved_model/corss_val/general_model/hp_seq_len/8\n",
      "saved_model/corss_val/general_model/hp_seq_len/9\n",
      "saved_model/corss_val/general_model/hp_seq_len/10\n",
      "saved_model/corss_val/general_model/hp_seq_len/11\n",
      "saved_model/corss_val/general_model/hp_seq_len/12\n"
     ]
    }
   ],
   "source": [
    "saving_models = []\n",
    "for s in seq_lengths_to_evaluate:\n",
    "    cur_saving_dir = os.path.join(saved_model_dir, str(s))\n",
    "    print(cur_saving_dir)\n",
    "    saving_models.append(cur_saving_dir)\n",
    "    if not os.path.exists(cur_saving_dir):\n",
    "        os.makedirs(cur_saving_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pd_list_full_with_rewards_original_seq4.pkl', 'rb') as f:\n",
    "    pd_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>choice</th>\n",
       "      <th>reward</th>\n",
       "      <th>time</th>\n",
       "      <th>payoff_structure</th>\n",
       "      <th>reward_1</th>\n",
       "      <th>reward_2</th>\n",
       "      <th>reward_3</th>\n",
       "      <th>reward_4</th>\n",
       "      <th>orig_choice_num</th>\n",
       "      <th>prev_choice</th>\n",
       "      <th>prev_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>612.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>742.0</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>92</td>\n",
       "      <td>61</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>966.0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>637.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>816.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>611.0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>601.0</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>579.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>606.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>82</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>87</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>593.0</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>597.0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>830.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>676.0</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>75</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>777.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>82</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>914.0</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>897.0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>73</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>598.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>47</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>646.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>71</td>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>664.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>73</td>\n",
       "      <td>51</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>938.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>752.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>73</td>\n",
       "      <td>46</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>41</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>903.0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "      <td>37</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>761.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>47</td>\n",
       "      <td>129</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>659.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>718.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>810.0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>585.0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>814.0</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>652.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>54</td>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>608.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>717.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>54</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>664.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>616.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>769.0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  choice  reward    time  payoff_structure  reward_1  reward_2  \\\n",
       "1       1       2      90  1076.0                 2        90        90   \n",
       "2       1       3      53   612.0                 2        80        84   \n",
       "3       1       4      24   742.0                 2        87        81   \n",
       "4       1       2      92   927.0                 2        86        92   \n",
       "5       1       2      78   966.0                 2        75        78   \n",
       "6       1       1      71   637.0                 2        71        78   \n",
       "7       1       1      75   644.0                 2        75        83   \n",
       "8       1       2      80   640.0                 2        77        80   \n",
       "9       1       2      80  1161.0                 2        70        80   \n",
       "10      1       2      91   953.0                 2        65        91   \n",
       "11      1       2      90   816.0                 2        77        90   \n",
       "12      1       4      29   611.0                 2        66        79   \n",
       "13      1       3      45  1152.0                 2        66        90   \n",
       "14      1       2      81   601.0                 2        67        81   \n",
       "15      1       2      75   579.0                 2        59        75   \n",
       "16      1       2      82   560.0                 2        67        82   \n",
       "17      1       2      82   606.0                 2        64        82   \n",
       "18      1       2      87   577.0                 2        61        87   \n",
       "19      1       2      85   593.0                 2        62        85   \n",
       "20      1       2      87   597.0                 2        55        87   \n",
       "21      1       2      87   830.0                 2        59        87   \n",
       "22      1       2      79   676.0                 2        56        79   \n",
       "23      1       2      75  1009.0                 2        57        75   \n",
       "24      1       1      61  1170.0                 2        61        75   \n",
       "25      1       3      40   587.0                 2        59        74   \n",
       "26      1       4      37   777.0                 2        50        82   \n",
       "27      1       2      72   914.0                 2        57        72   \n",
       "28      1       2      73   897.0                 2        60        73   \n",
       "29      1       1      66  1569.0                 2        66        71   \n",
       "30      1       2      57   583.0                 2        65        57   \n",
       "..    ...     ...     ...     ...               ...       ...       ...   \n",
       "118     1       3      71   598.0                 2        33        47   \n",
       "119     1       3      65  1048.0                 2        29        45   \n",
       "120     1       2      43   646.0                 2        29        43   \n",
       "121     1       1      37   664.0                 2        37        32   \n",
       "122     1       4      48   938.0                 2        37        48   \n",
       "123     1       3      73   752.0                 2        33        35   \n",
       "124     1       3      66   750.0                 2        37        35   \n",
       "125     1       3      59   903.0                 2        45        41   \n",
       "126     1       3      69   761.0                 2        29        37   \n",
       "127     1       3      75   600.0                 2        34        40   \n",
       "128     1       3      67   659.0                 2        32        40   \n",
       "129     1       3      63   718.0                 2        43        40   \n",
       "130     1       3      74   810.0                 2        48        44   \n",
       "131     1       3      70   585.0                 2        35        45   \n",
       "132     1       3      77  1064.0                 2        39        37   \n",
       "133     1       3      70   814.0                 2        42        35   \n",
       "134     1       3      78   652.0                 2        34        34   \n",
       "135     1       3      74   587.0                 2        29        39   \n",
       "136     1       3      70   608.0                 2        33        28   \n",
       "137     1       3      68   717.0                 2        33        31   \n",
       "138     1       3      67   664.0                 2        33        33   \n",
       "139     1       3      63   951.0                 2        37        26   \n",
       "140     1       3      65   665.0                 2        33        34   \n",
       "141     1       1      36   616.0                 2        36        35   \n",
       "142     1       2      38  1295.0                 2        44        38   \n",
       "143     1       4      48   680.0                 2        47        35   \n",
       "144     1       3      61   749.0                 2        46        47   \n",
       "145     1       3      70   644.0                 2        46        35   \n",
       "146     1       3      60   769.0                 2        46        44   \n",
       "147     1       3      56   657.0                 2        39        35   \n",
       "\n",
       "     reward_3  reward_4  orig_choice_num  prev_choice  prev_reward  \n",
       "1          46        18                1            1           84  \n",
       "2          53        28                2            2           90  \n",
       "3          50        24                3            3           53  \n",
       "4          61        28                4            4           24  \n",
       "5          55        30                5            2           92  \n",
       "6          50        34                6            2           78  \n",
       "7          58        43                7            1           71  \n",
       "8          52        30                8            1           75  \n",
       "9          43        28                9            2           80  \n",
       "10         49        29               10            2           80  \n",
       "11         53        30               11            2           91  \n",
       "12         44        29               12            2           90  \n",
       "13         45        30               13            4           29  \n",
       "14         45        35               14            3           45  \n",
       "15         39        32               15            2           81  \n",
       "16         54        33               16            2           75  \n",
       "17         51        20               17            2           82  \n",
       "18         42        28               18            2           82  \n",
       "19         50        27               19            2           87  \n",
       "20         46        32               20            2           85  \n",
       "21         51        34               21            2           87  \n",
       "22         50        38               22            2           87  \n",
       "23         45        34               23            2           79  \n",
       "24         47        34               24            2           75  \n",
       "25         40        33               25            1           61  \n",
       "26         42        37               26            3           40  \n",
       "27         48        41               27            4           37  \n",
       "28         48        37               28            2           72  \n",
       "29         47        38               29            2           73  \n",
       "30         48        34               30            1           66  \n",
       "..        ...       ...              ...          ...          ...  \n",
       "118        71        35              120            3           70  \n",
       "119        65        39              121            3           71  \n",
       "120        71        45              122            3           65  \n",
       "121        73        51              123            2           43  \n",
       "122        65        48              124            1           37  \n",
       "123        73        46              125            4           48  \n",
       "124        66        41              126            3           73  \n",
       "125        59        37              127            3           66  \n",
       "126        69        40              128            3           59  \n",
       "127        75        47              129            3           69  \n",
       "128        67        40              130            3           75  \n",
       "129        63        42              131            3           67  \n",
       "130        74        37              132            3           63  \n",
       "131        70        49              133            3           74  \n",
       "132        77        47              134            3           70  \n",
       "133        70        46              135            3           77  \n",
       "134        78        56              136            3           70  \n",
       "135        74        54              137            3           78  \n",
       "136        70        46              138            3           74  \n",
       "137        68        54              139            3           70  \n",
       "138        67        60              140            3           68  \n",
       "139        63        56              141            3           67  \n",
       "140        65        57              142            3           63  \n",
       "141        60        51              143            3           65  \n",
       "142        60        55              144            1           36  \n",
       "143        62        48              145            2           38  \n",
       "144        61        57              146            4           48  \n",
       "145        70        43              147            3           61  \n",
       "146        60        59              148            3           70  \n",
       "147        56        51              149            3           60  \n",
       "\n",
       "[147 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TRAIN_NUM_STEPS = 4\n",
    "# seq_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use previous seq of 4's to be consistent  \n",
    "with open('huge_pd_shuffled_with_rewards_original_seq4_SHUFFLED.pkl', 'rb') as f:\n",
    "    huge_pd = pickle.load(f)\n",
    "\n",
    "with open('cross_validation/diff_seq_lengths/all_huge_pd_shuffled_with_rewards_original_seq2_to_seq12_SHUFFLED_LIST.pkl', 'rb') as f:\n",
    "    huge_pd_hp_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(huge_pd.user.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the kfolded pars\n",
    "with open('cross_validation/payoff2_train_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff2_train_participants_5fold_list = pickle.load(f)\n",
    "\n",
    "with open('cross_validation/payoff2_test_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff2_test_participants_5fold_list = pickle.load(f)\n",
    "\n",
    "with open('cross_validation/payoff3_train_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff3_train_participants_5fold_list = pickle.load(f)\n",
    "\n",
    "with open('cross_validation/payoff3_test_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff3_test_participants_5fold_list = pickle.load(f)\n",
    "\n",
    "with open('cross_validation/payoff4_train_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff4_train_participants_5fold_list = pickle.load(f)\n",
    "    \n",
    "with open('cross_validation/payoff4_test_participants_5fold_list.pkl', 'rb') as f:\n",
    "    payoff4_test_participants_5fold_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_kfold_split(huge_pd, kfold_train_payoff2, kfold_train_payoff3, kfold_train_payoff4, kfold_test_payoff2, kfold_test_payoff3, kfold_test_payoff4, k=5):\n",
    "    \"\"\"\n",
    "    gets all the folding (trains and tests pars) and returns (train_data, test_data) in the same amount of folds (if theres 5 folds then 5 train_data etc)\n",
    "    indices are corresponding ! ([0] in train comes with [0] in test)\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for i in range(k):\n",
    "        train_data.append(huge_pd[(huge_pd['user'].isin(kfold_train_payoff2[i]))|\n",
    "                                (huge_pd['user'].isin(kfold_train_payoff3[i]))|\n",
    "                                (huge_pd['user'].isin(kfold_train_payoff4[i]))].copy())\n",
    "        \n",
    "        test_data.append(huge_pd[(huge_pd['user'].isin(kfold_test_payoff2[i]))|\n",
    "                                (huge_pd['user'].isin(kfold_test_payoff3[i]))|\n",
    "                                (huge_pd['user'].isin(kfold_test_payoff4[i]))].copy())\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cur_data = huge_pd.copy()\n",
    "cur_data['choice'] = cur_data.choice.apply(lambda x: x - 1)\n",
    "cur_data['prev_choice'] = cur_data.prev_choice.apply(lambda x: x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = my_kfold_split(cur_data, \n",
    "                                       payoff2_train_participants_5fold_list,\n",
    "                                       payoff3_train_participants_5fold_list,\n",
    "                                       payoff4_train_participants_5fold_list,\n",
    "                                       payoff2_test_participants_5fold_list,\n",
    "                                       payoff3_test_participants_5fold_list,\n",
    "                                       payoff4_test_participants_5fold_list,\n",
    "                                       )\n",
    "# sanity checks\n",
    "assert(train_data[0].shape!=train_data[1].shape)\n",
    "assert(train_data[0].shape!=train_data[2].shape)\n",
    "assert(train_data[0].shape!=train_data[3].shape)\n",
    "assert(train_data[0].shape!=train_data[4].shape)\n",
    "\n",
    "assert(train_data[1].shape!=train_data[3].shape)\n",
    "assert(train_data[1].shape!=train_data[4].shape)\n",
    "\n",
    "assert(train_data[2].shape!=train_data[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_data(train_data, test_data, seq_length):\n",
    "    fold_X_train = []\n",
    "    fold_y_train = []\n",
    "    fold_X_test = []\n",
    "    fold_y_test = []\n",
    "\n",
    "    for train, test in zip(train_data, test_data):\n",
    "        X = train.drop(columns=['index', 'choice', 'user', 'time', 'reward', 'payoff_structure', 'reward_1', 'reward_2', 'reward_3', 'reward_4'])\n",
    "        X_prev = to_categorical(X.prev_choice, dtype='int64')\n",
    "        y = train.choice\n",
    "        num_of_classes = len(y.unique())\n",
    "        y_train = to_categorical(y, dtype='int64')\n",
    "        new_X = []\n",
    "        for prev_choice, prev_reward in zip(X_prev, X.prev_reward):\n",
    "            new_i = np.append(prev_choice, prev_reward)\n",
    "            new_X.append(new_i)\n",
    "        X_train = np.array(new_X)\n",
    "\n",
    "        possible_samples_train = int(X_train.shape[0] / seq_length)\n",
    "        possible_labels_train = int(y_train.shape[0] / seq_length)\n",
    "\n",
    "\n",
    "        # reshape X to be [samples, time steps, features]\n",
    "        X_train = np.reshape(X_train, (possible_samples_train, seq_length, X_train.shape[1]))\n",
    "        fold_X_train.append(X_train)\n",
    "        y_cat_train = np.reshape(y_train, (possible_samples_train, seq_length, y_train.shape[1]))\n",
    "        fold_y_train.append(y_cat_train)\n",
    "\n",
    "        ########################################################################\n",
    "        ### TEST ###############################################\n",
    "\n",
    "        X = test.drop(columns=['index', 'choice', 'user', 'time', 'reward', 'payoff_structure', 'reward_1', 'reward_2', 'reward_3', 'reward_4'])\n",
    "        X_prev = to_categorical(X.prev_choice, dtype='int64')\n",
    "        y = test.choice\n",
    "        num_of_classes = len(y.unique())\n",
    "        y_test = to_categorical(y, dtype='int64')\n",
    "        new_X = []\n",
    "        for prev_choice, prev_reward in zip(X_prev, X.prev_reward):\n",
    "            new_i = np.append(prev_choice, prev_reward)\n",
    "            new_X.append(new_i)\n",
    "        X_test = np.array(new_X)\n",
    "\n",
    "        possible_labels_test = int(y_test.shape[0] / seq_length)\n",
    "        possible_samples_test = int(X_test.shape[0] / seq_length)\n",
    "\n",
    "        X_test = np.reshape(X_test, (possible_samples_test, seq_length, X_test.shape[1]))\n",
    "        fold_X_test.append(X_test)\n",
    "        y_cat_test = np.reshape(y_test, (possible_labels_test, seq_length, y_test.shape[1]))\n",
    "        fold_y_test.append(y_cat_test)\n",
    "\n",
    "    \n",
    "    return  fold_X_train, fold_y_train, fold_X_test, fold_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,all_x,all_y, is_training, output_size, dropout=1.0, batch_size=TRAIN_BATCHES, return_seqence=False):\n",
    "\n",
    "        # self.x = tf.placeholder(dtype=tf.int32, shape=[None, 4, 5], name='X_placeholder')\n",
    "        # self.y = tf.placeholder(dtype=tf.int32, shape=[None, 4], name='Y_placeholder')\n",
    "\n",
    "        # A dataset from a tensor\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(all_x)\n",
    "        # Divide the dataset into batches. Once you reach the last batch which won't be 512, the dataset will know exactly which elements remain and should be passed as a batch.\n",
    "        dataset = dataset.batch(TRAIN_BATCHES)\n",
    "        # An iterator that can be reinitialized over and over again, therefore having a new shuffle of the data each time\n",
    "        self.iterator = dataset.make_initializable_iterator()\n",
    "        # A node that can be run to obtain the next element in the dataset. However, this node will be linked in the model so obtaining the next element will be done automatically\n",
    "        self.data_X = self.iterator.get_next()\n",
    "\n",
    "        labels = tf.data.Dataset.from_tensor_slices(all_y)\n",
    "        # Shuffle the dataset with some arbitrary buffer size\n",
    "        # dataset = dataset.shuffle(buffer_size=10)\n",
    "        # Divide the dataset into batches. Once you reach the last batch which won't be 512, the dataset will know exactly which elements remain and should be passed as a batch.\n",
    "        labels = labels.batch(TRAIN_BATCHES)\n",
    "        # An iterator that can be reinitialized over and over again, therefore having a new shuffle of the data each time\n",
    "        self.labels_iterator = labels.make_initializable_iterator()\n",
    "        # A node that can be run to obtain the next element in the dataset. However, this node will be linked in the model so obtaining the next element will be done automatically\n",
    "        self.data_Y = self.labels_iterator.get_next()\n",
    "\n",
    "\n",
    "\n",
    "        self.seq_len = tf.placeholder(dtype=tf.int32,name='sequence_len')\n",
    "\n",
    "\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(HIDDEN_SIZE)\n",
    "        self.current_batch_size = tf.shape(self.data_X)[0]\n",
    "        init_state = cell.zero_state(self.current_batch_size, tf.float32)\n",
    "        self.output, self.states = tf.nn.dynamic_rnn(cell=cell, inputs=tf.cast(self.data_X, tf.float32), initial_state=init_state)\n",
    "\n",
    "        # tf.keras.layers.Dense(output_size, activation=tf.nn.softmax)\n",
    "\n",
    "        # reshape to (batch_size * num_steps, HIDDEN_SIZE)\n",
    "        output = tf.reshape(self.output, [-1, HIDDEN_SIZE])\n",
    "\n",
    "        softmax_w = tf.Variable(tf.random_uniform([HIDDEN_SIZE, output_size]))\n",
    "        softmax_b = tf.Variable(tf.random_uniform([output_size]))\n",
    "\n",
    "        self.logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "        # Reshape logits to be a 3-D tensor for sequence loss\n",
    "        # if return_seqence:\n",
    "        self.logits_reshaped = tf.reshape(self.logits, [self.current_batch_size, self.seq_len, output_size])[:,-1,:]\n",
    "\n",
    "        # TODO: I need return_sequence false , which means I only needs the last output/hidden state\n",
    "        self.softmax_out = tf.nn.softmax(self.logits)\n",
    "        self.softmax_out_reshaped = tf.reshape(self.softmax_out, [self.current_batch_size,seq_length,output_size])[:,-1,:]\n",
    "\n",
    "        loss = tf.keras.losses.categorical_crossentropy(tf.cast(self.data_Y,tf.float32), self.logits_reshaped,from_logits=True)\n",
    "\n",
    "\n",
    "        self.cost = tf.reduce_sum(loss)\n",
    "\n",
    "        # TODO: continue\n",
    "        # get the prediction accuracy\n",
    "        self.predict = tf.cast(tf.argmax(self.softmax_out, axis=1), tf.int64)\n",
    "        self.predict_return_sequence_false = tf.cast(tf.argmax(self.softmax_out_reshaped, axis=1), tf.int64)\n",
    "\n",
    "        # self.correct_prediction = tf.equal(tf.argmax(self.predict , 1), tf.argmax(self.data_Y, 1))\n",
    "        self.correct_prediction = tf.equal(self.predict, tf.reshape(self.data_Y, [-1]))\n",
    "        self.correct_prediction_return_sequence_false = tf.equal(self.predict_return_sequence_false, tf.argmax(self.data_Y, 1))\n",
    "\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        self.accuracy_return_sequence_false = tf.reduce_mean(tf.cast(self.correct_prediction_return_sequence_false, tf.float32))\n",
    "        # tf.keras.metrics.categorical_accuracy(y_true,y_pred)\n",
    "\n",
    "        if not is_training:\n",
    "            return\n",
    "\n",
    "        # self.optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.9999).minimize(self.cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SinglesModel(object):\n",
    "    def __init__(self,is_training, output_size, dropout=1.0, batch_size=TRAIN_BATCHES, return_seqence=False, single_test=False):\n",
    "\n",
    "        self.data_X = tf.placeholder(dtype=tf.int64, shape=[1, 4, 5], name='X_placeholder')\n",
    "        self.data_Y = tf.placeholder(dtype=tf.int64, shape=[1, 4], name='Y_placeholder')\n",
    "        \n",
    "        self.seq_len = tf.placeholder(dtype=tf.int32,name='sequence_len')\n",
    "\n",
    "\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(HIDDEN_SIZE)\n",
    "        self.current_batch_size = tf.shape(self.data_X)[0]\n",
    "        init_state = cell.zero_state(self.current_batch_size, tf.float32)\n",
    "        self.output, self.states = tf.nn.dynamic_rnn(cell=cell, inputs=tf.cast(self.data_X, tf.float32), initial_state=init_state)\n",
    "\n",
    "        output = tf.reshape(self.output, [-1, HIDDEN_SIZE])\n",
    "\n",
    "        softmax_w = tf.Variable(tf.random_uniform([HIDDEN_SIZE, output_size]))\n",
    "        softmax_b = tf.Variable(tf.random_uniform([output_size]))\n",
    "\n",
    "        self.logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "        # Reshape logits to be a 3-D tensor for sequence loss\n",
    "        # if return_seqence:\n",
    "        self.logits_reshaped = tf.reshape(self.logits, [self.current_batch_size, self.seq_len, output_size])[:,-1,:]\n",
    "\n",
    "        # TODO: I need return_sequence false , which means I only needs the last output/hidden state\n",
    "        self.softmax_out = tf.nn.softmax(self.logits)\n",
    "        self.softmax_out_reshaped = tf.reshape(self.softmax_out, [self.current_batch_size,seq_length,output_size])[:,-1,:]\n",
    "\n",
    "\n",
    "        loss = tf.keras.losses.categorical_crossentropy(tf.cast(self.data_Y,tf.float32), self.logits_reshaped,from_logits=True)\n",
    "\n",
    "\n",
    "        self.cost = tf.reduce_sum(loss)\n",
    "\n",
    "        # TODO: continue\n",
    "        # get the prediction accuracy\n",
    "        self.predict = tf.cast(tf.argmax(self.softmax_out, axis=1), tf.int64)\n",
    "        self.predict_return_sequence_false = tf.cast(tf.argmax(self.softmax_out_reshaped, axis=1), tf.int64)\n",
    "\n",
    "        # self.correct_prediction = tf.equal(tf.argmax(self.predict , 1), tf.argmax(self.data_Y, 1))\n",
    "        self.correct_prediction = tf.equal(self.predict, tf.reshape(self.data_Y, [-1]))\n",
    "        self.correct_prediction_return_sequence_false = tf.equal(self.predict_return_sequence_false, tf.argmax(self.data_Y, 1))\n",
    "\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        self.accuracy_return_sequence_false = tf.reduce_mean(tf.cast(self.correct_prediction_return_sequence_false, tf.float32))\n",
    "        # tf.keras.metrics.categorical_accuracy(y_true,y_pred)\n",
    "\n",
    "        if not is_training:\n",
    "            return\n",
    "        # self.optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.9999).minimize(self.cost)\n",
    "    \n",
    "    def test_single(self,all_x, all_y, model_path, output_size=4, print_iter=50, print_results=True):\n",
    "        # setup data and models\n",
    "    #     Model(all_x,all_y,is_training=False, output_size=4, batch_size=TRAIN_BATCHES, test_single=True)\n",
    "#         m = model\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run([init_op])\n",
    "            saver.restore(sess, model_path)\n",
    "            counter = 0\n",
    "            # print(\"will run for {} steps in total\".format(len(all_x)))\n",
    "            accs_over_batches = []\n",
    "            loss_over_batches = []\n",
    "            predictions_over_batches = []\n",
    "            correct_predictions = []\n",
    "            hidden_states = []\n",
    "            logits_list = []\n",
    "            softmaxes = []\n",
    "            outputs = []\n",
    "            output, states, \\\n",
    "            logits, logits_reshaped, softmax_out, softmax_out_reshaped,\\\n",
    "            predict, predict_return_sequence_false, correct_prediction, correct_prediction_return_sequence_false,\\\n",
    "            accuracy, accuracy_return_sequence_false,\\\n",
    "                cost = sess.run(\n",
    "                [\n",
    "                 self.output, self.states,\n",
    "                 self.logits, self.logits_reshaped, self.softmax_out, self.softmax_out_reshaped,\n",
    "                 self.predict, self.predict_return_sequence_false, self.correct_prediction, self.correct_prediction_return_sequence_false,\n",
    "                 self.accuracy, self.accuracy_return_sequence_false,\n",
    "                 self.cost],\n",
    "                feed_dict={\n",
    "                           self.seq_len: TRAIN_NUM_STEPS, self.data_X:all_x, self.data_Y:all_y\n",
    "                           })\n",
    "            # print()\n",
    "            counter = counter + 1\n",
    "            accs_over_batches.append(accuracy_return_sequence_false)\n",
    "            loss_over_batches.append(cost)\n",
    "            predictions_over_batches.append(predict_return_sequence_false)\n",
    "            correct_predictions.append(correct_prediction_return_sequence_false)\n",
    "            hidden_states.append(states)\n",
    "            logits_list.append(logits_reshaped)\n",
    "            softmaxes.append(softmax_out_reshaped)\n",
    "            outputs.append(output)\n",
    "\n",
    "            if print_results:\n",
    "                print(\"---------------------------------------------------------------\")\n",
    "                # print(accs_over_batches[-1])\n",
    "                print(np.mean(accs_over_batches))\n",
    "                print(\"loss:\")\n",
    "                # print(loss_over_batches[-1])\n",
    "                print(np.mean(loss_over_batches))\n",
    "            # do a final save\n",
    "            # saver.save(sess, save_path)\n",
    "\n",
    "            return accs_over_batches, loss_over_batches, predictions_over_batches, correct_predictions, hidden_states, logits_list, softmaxes, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(all_x, all_y, save_path, output_size=4, print_iter=50):\n",
    "    # setup data and models\n",
    "    m = Model(all_x,all_y,is_training=True, output_size=4, batch_size=TRAIN_BATCHES)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run([init_op])\n",
    "        saver = tf.train.Saver()\n",
    "        accs_over_epochs = []\n",
    "        loss_over_epochs = []\n",
    "        counter = 0\n",
    "        # print(\"will run for {} steps in total\".format(len(all_x)))\n",
    "        for epoch in range(TRAIN_EPOCHS):\n",
    "            accs_over_batches = []\n",
    "            loss_over_batches = []\n",
    "            sess.run([m.iterator.initializer, m.labels_iterator.initializer])\n",
    "            try:\n",
    "                # As long as there are elements execute the block below\n",
    "                while True:\n",
    "                    \"\"\"\n",
    "                    xs and ys are the current batches\n",
    "                    output and states are the returned values of tf.nn.dynamic_rnn\n",
    "                    \"\"\"\n",
    "                    xs,ys, \\\n",
    "                    output, states, \\\n",
    "                    logits, logits_reshaped, softmax_out, softmax_out_reshaped,\\\n",
    "                    predict, predict_return_sequence_false, correct_prediction, correct_prediction_return_sequence_false,\\\n",
    "                    accuracy, accuracy_return_sequence_false,\\\n",
    "                        cost, _= sess.run(\n",
    "                        [m.data_X,m.data_Y,\n",
    "                         m.output, m.states,\n",
    "                         m.logits, m.logits_reshaped, m.softmax_out, m.softmax_out_reshaped,\n",
    "                         m.predict, m.predict_return_sequence_false, m.correct_prediction, m.correct_prediction_return_sequence_false,\n",
    "                         m.accuracy, m.accuracy_return_sequence_false,\n",
    "                         m.cost,\n",
    "                         m.optimizer],\n",
    "                        feed_dict={\n",
    "                                   m.seq_len: TRAIN_NUM_STEPS\n",
    "                                   })\n",
    "                    # print()\n",
    "                    counter = counter +1\n",
    "                    accs_over_batches.append(accuracy_return_sequence_false)\n",
    "                    loss_over_batches.append(cost)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"finished epoc {}, acc {} loss {}\".format(epoch, np.mean(accs_over_batches),np.mean(loss_over_batches)))\n",
    "                accs_over_epochs.append(np.mean(accs_over_batches))\n",
    "                loss_over_epochs.append(np.mean(loss_over_batches))\n",
    "                print(accs_over_batches)\n",
    "                pass\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(accs_over_epochs[-1])\n",
    "        print(np.mean(accs_over_epochs))\n",
    "        print(\"loss:\")\n",
    "        print(loss_over_epochs[-1])\n",
    "        print(np.mean(loss_over_epochs))\n",
    "        # do a final save\n",
    "        saver.save(sess, save_path)\n",
    "\n",
    "        return accs_over_epochs, loss_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(all_x, all_y, model_path, output_size=4, print_iter=50, print_results=True):\n",
    "    # setup data and models\n",
    "    m = Model(all_x,all_y,is_training=False, output_size=4, batch_size=TRAIN_BATCHES)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run([init_op])\n",
    "        saver.restore(sess, model_path)\n",
    "        counter = 0\n",
    "        # print(\"will run for {} steps in total\".format(len(all_x)))\n",
    "        accs_over_batches = []\n",
    "        loss_over_batches = []\n",
    "        predictions_over_batches = []\n",
    "        correct_predictions = []\n",
    "        hidden_states = []\n",
    "        logits_list = []\n",
    "        softmaxes = []\n",
    "        outputs = []\n",
    "        sess.run([m.iterator.initializer, m.labels_iterator.initializer])\n",
    "        try:\n",
    "            # As long as there are elements execute the block below\n",
    "            while True:\n",
    "                \"\"\"\n",
    "                xs and ys are the current batches\n",
    "                output and states are the returned values of tf.nn.dynamic_rnn\n",
    "                \"\"\"\n",
    "                xs,ys, \\\n",
    "                output, states, \\\n",
    "                logits, logits_reshaped, softmax_out, softmax_out_reshaped,\\\n",
    "                predict, predict_return_sequence_false, correct_prediction, correct_prediction_return_sequence_false,\\\n",
    "                accuracy, accuracy_return_sequence_false,\\\n",
    "                    cost = sess.run(\n",
    "                    [m.data_X,m.data_Y,\n",
    "                     m.output, m.states,\n",
    "                     m.logits, m.logits_reshaped, m.softmax_out, m.softmax_out_reshaped,\n",
    "                     m.predict, m.predict_return_sequence_false, m.correct_prediction, m.correct_prediction_return_sequence_false,\n",
    "                     m.accuracy, m.accuracy_return_sequence_false,\n",
    "                     m.cost],\n",
    "                    feed_dict={\n",
    "                               m.seq_len: TRAIN_NUM_STEPS\n",
    "                               })\n",
    "                # print()\n",
    "                counter = counter + 1\n",
    "                accs_over_batches.append(accuracy_return_sequence_false)\n",
    "                loss_over_batches.append(cost)\n",
    "                predictions_over_batches.append(predict_return_sequence_false)\n",
    "                correct_predictions.append(correct_prediction_return_sequence_false)\n",
    "                hidden_states.append(states)\n",
    "                logits_list.append(logits_reshaped)\n",
    "                softmaxes.append(softmax_out_reshaped)\n",
    "                outputs.append(output)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            if print_results:\n",
    "                print(\"finished testing, acc {} loss {}\".format(np.mean(accs_over_batches),np.mean(loss_over_batches)))\n",
    "                print(accs_over_batches)\n",
    "            pass\n",
    "        if print_results:\n",
    "            print(\"---------------------------------------------------------------\")\n",
    "            # print(accs_over_batches[-1])\n",
    "            print(np.mean(accs_over_batches))\n",
    "            print(\"loss:\")\n",
    "            # print(loss_over_batches[-1])\n",
    "            print(np.mean(loss_over_batches))\n",
    "        # do a final save\n",
    "        # saver.save(sess, save_path)\n",
    "\n",
    "        return accs_over_batches, loss_over_batches, predictions_over_batches, correct_predictions, hidden_states, logits_list, softmaxes, outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the activations and predictions per person    \n",
    " - Need to load each fold model, use it for the testing, save and evantually average across all folds\n",
    "<a id=\"testing_per_participant\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "with open('pd_list_full_with_rewards_original_seq4.pkl', 'rb') as f:\n",
    "    pd_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each person , make a prediction at time t and get the Results data scrutre, states & output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_last_seq(person_df, choice_number, seq_len, debug_prints=False):\n",
    "    \"\"\"\n",
    "    Gets a person's data and a choice number and returns a sequence of previous 4 (or seq_length) choices made (maybe not 4 (seq_length) consecutives)\n",
    "    \"\"\"\n",
    "    if choice_number < seq_len:\n",
    "        if debug_prints: print(\"must be {} and more to get a sequence\".format(seq_len))\n",
    "        return -2\n",
    "    ind = np.where(person_df[\"orig_choice_num\"] == choice_number)\n",
    "    if len(ind[0]) == 0:\n",
    "        if debug_prints: print(\"choice number {} not found\".format(choice_number))\n",
    "        return -9\n",
    "    elif len(ind[0]) > 1:\n",
    "        if debug_prints: print(\"FOR SOME REASON THERE'S MORE THAN ONE CHOICE NUMBER LIKE {}\".format(choice_number))\n",
    "        return -1\n",
    "    # got here so I found the choice number , now lets check if we have 4 previous choices\n",
    "    seq = []\n",
    "    for i in range(ind[0][0] - seq_len + 1, ind[0][0] + 1, 1):\n",
    "        seq.append(i)\n",
    "\n",
    "    return person_df.iloc[seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_data_sequence(seq_df, seq_len):\n",
    "    \"\"\"\n",
    "    gets a SINGLE sequence in df form and returns it in a train/test ready form (numpy) X and y\n",
    "    \"\"\"\n",
    "    cur_data = seq_df.copy()\n",
    "    cur_data['choice'] = cur_data.choice.apply(lambda x: x - 1)\n",
    "    cur_data['prev_choice'] = cur_data.prev_choice.apply(lambda x: x - 1)\n",
    "    X = cur_data.drop(\n",
    "        columns=['choice', 'user', 'time', 'reward', 'payoff_structure', 'reward_1', 'reward_2', 'reward_3', 'reward_4',\n",
    "                 'orig_choice_num'])\n",
    "    X_prev = to_categorical(X.prev_choice, num_classes=4, dtype='int64')\n",
    "    y = cur_data.choice\n",
    "    num_of_classes = len(y.unique())\n",
    "    y = to_categorical(y, num_classes=4, dtype='int64')\n",
    "\n",
    "    new_X = []\n",
    "    for prev_choice, prev_reward in zip(X_prev, X.prev_reward):\n",
    "        new_i = np.append(prev_choice, prev_reward)\n",
    "        new_X.append(new_i)\n",
    "    new_X = np.array(new_X)\n",
    "\n",
    "    # reshape X to be [samples, time steps, features]\n",
    "    X_reshaped = np.reshape(new_X, (1, seq_length, new_X.shape[1]))\n",
    "    y_reshaped = np.reshape(y, (1, seq_length, y.shape[1]))\n",
    "\n",
    "    return X_reshaped, y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I go over pd_list , which is the full list of dfs for each person (WITHOUT NAs). For each time t , I get the previous 4 steps and if there is no choice at time t I place -1. \n",
    "If there is a choice, I do predict for time t using previous 4\n",
    "\"\"\"\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
    "def test_per_par(set_of_pars, fold_number, save_path):\n",
    "    \"\"\"\n",
    "    run the extraction of pred/acc/activation etc.\n",
    "    gets the participants (actual numbers) that are in a certain fold. (folder number will be just for printing)\n",
    "\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    total_actual_predictions = 0\n",
    "    total_predicted_correct = 0\n",
    "    persons_predictions_expr = []\n",
    "    persons_true_false_predictions = []\n",
    "    persons_activations = []\n",
    "    curr_time = dt.datetime.now()\n",
    "    person_count = 1\n",
    "    for person in pd_list:\n",
    "        if person.user.unique()[0] in set_of_pars:\n",
    "            cur_person_activations = []\n",
    "            predictions_expr = []\n",
    "            predicted_correct = 0\n",
    "            actual_predictions = 0\n",
    "            true_false_predictions = np.zeros(150)\n",
    "            for i in range(0, 150):\n",
    "                tf.reset_default_graph()\n",
    "                m = get_last_seq(person, i, seq_len=seq_length)\n",
    "                if not isinstance(m,pd.DataFrame):\n",
    "                    if m == -9:\n",
    "                        predictions_expr.append(-1)\n",
    "                        true_false_predictions[i] = -1\n",
    "                        cur_person_activations.append(-1)\n",
    "                        continue\n",
    "                    elif m == -2:\n",
    "                        predictions_expr.append(-1)\n",
    "                        true_false_predictions[i] = -1\n",
    "                        cur_person_activations.append(-1)\n",
    "                        continue\n",
    "                    elif m == -1:\n",
    "                        true_false_predictions[i] = -1\n",
    "                        cur_person_activations.append(-1)\n",
    "                        continue\n",
    "                X_expr,y_expr = create_data_sequence(m,seq_len=seq_length)\n",
    "                x = X_expr[:,:,:].copy()\n",
    "                y = y_expr[:,-1,:].copy()\n",
    "                model1 = SinglesModel(is_training=False, output_size=4, batch_size=TRAIN_BATCHES, single_test=True)\n",
    "\n",
    "                current_acc, current_loss, class_pred, correct_prediction, hidden_states, logits_test, softmax_test, outputs_test = model1.test_single(x, y, save_path, print_results=False)\n",
    "                # notice that h[0] is correct where theres only one cell's hidden state, if I want the 4-5 steps, I will need to get just h \n",
    "                # FIXED : now adding outputs_test - which is 4 hidden states, last one is the same as hidden_states[0].h[0]\n",
    "                cur_person_activations.append(outputs_test)\n",
    "                predictions_expr.append(class_pred[0][0])\n",
    "                actual_predictions += 1\n",
    "                if correct_prediction[0][0]:\n",
    "                    predicted_correct += 1\n",
    "                    # True for a correct prediction, False otherwise\n",
    "                    true_false_predictions[i] = correct_prediction[0][0]\n",
    "\n",
    "            persons_activations.append(cur_person_activations)\n",
    "            persons_true_false_predictions.append(true_false_predictions)\n",
    "            persons_predictions_expr.append(predictions_expr)\n",
    "            total_actual_predictions += actual_predictions\n",
    "            total_predicted_correct += predicted_correct\n",
    "            seconds = (float((dt.datetime.now() - curr_time).seconds))\n",
    "            curr_time = dt.datetime.now()\n",
    "            print(\"finished person {} from fold #{} in {} seconds\".format(person_count, fold_number, seconds))\n",
    "            person_count+=1\n",
    "    \n",
    "    results = persons_true_false_predictions,persons_predictions_expr,total_actual_predictions,total_predicted_correct, persons_activations\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_model/corss_val/general_model/fold4/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# def get_available_gpus():\n",
    "#     local_device_protos = device_lib.list_local_devices()\n",
    "#     return [x.name for x in local_device_protos]\n",
    "\n",
    "# get_available_gpus()\n",
    "# with tf.device('/gpu:{}'.format(i)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 1 from fold #0 in 35.0 seconds\n",
      "finished person 2 from fold #0 in 37.0 seconds\n",
      "finished person 3 from fold #0 in 38.0 seconds\n",
      "finished person 4 from fold #0 in 37.0 seconds\n",
      "finished person 5 from fold #0 in 38.0 seconds\n",
      "finished person 6 from fold #0 in 39.0 seconds\n",
      "finished person 7 from fold #0 in 37.0 seconds\n",
      "finished person 8 from fold #0 in 35.0 seconds\n",
      "finished person 9 from fold #0 in 36.0 seconds\n",
      "finished person 10 from fold #0 in 36.0 seconds\n",
      "finished person 11 from fold #0 in 36.0 seconds\n",
      "finished person 12 from fold #0 in 36.0 seconds\n",
      "finished person 13 from fold #0 in 36.0 seconds\n",
      "finished person 14 from fold #0 in 35.0 seconds\n",
      "finished person 15 from fold #0 in 34.0 seconds\n",
      "finished person 16 from fold #0 in 35.0 seconds\n",
      "finished person 17 from fold #0 in 35.0 seconds\n",
      "finished person 18 from fold #0 in 36.0 seconds\n",
      "finished person 19 from fold #0 in 34.0 seconds\n",
      "finished person 20 from fold #0 in 35.0 seconds\n",
      "finished person 21 from fold #0 in 35.0 seconds\n",
      "finished person 22 from fold #0 in 35.0 seconds\n",
      "finished person 23 from fold #0 in 35.0 seconds\n",
      "finished person 24 from fold #0 in 38.0 seconds\n",
      "finished person 25 from fold #0 in 35.0 seconds\n",
      "finished person 26 from fold #0 in 31.0 seconds\n",
      "finished person 27 from fold #0 in 36.0 seconds\n",
      "finished person 28 from fold #0 in 34.0 seconds\n",
      "finished person 29 from fold #0 in 36.0 seconds\n",
      "finished person 30 from fold #0 in 36.0 seconds\n",
      "finished person 31 from fold #0 in 36.0 seconds\n",
      "finished person 32 from fold #0 in 35.0 seconds\n",
      "finished person 33 from fold #0 in 35.0 seconds\n",
      "finished person 34 from fold #0 in 34.0 seconds\n",
      "finished person 35 from fold #0 in 37.0 seconds\n",
      "finished person 36 from fold #0 in 36.0 seconds\n",
      "finished person 37 from fold #0 in 35.0 seconds\n",
      "finished person 38 from fold #0 in 35.0 seconds\n",
      "finished person 39 from fold #0 in 36.0 seconds\n",
      "finished person 40 from fold #0 in 35.0 seconds\n",
      "finished person 41 from fold #0 in 35.0 seconds\n",
      "finished person 42 from fold #0 in 36.0 seconds\n",
      "finished person 43 from fold #0 in 33.0 seconds\n",
      "finished person 44 from fold #0 in 30.0 seconds\n",
      "finished person 45 from fold #0 in 23.0 seconds\n",
      "finished person 46 from fold #0 in 36.0 seconds\n",
      "finished person 47 from fold #0 in 36.0 seconds\n",
      "finished person 48 from fold #0 in 36.0 seconds\n",
      "finished person 49 from fold #0 in 35.0 seconds\n",
      "finished person 50 from fold #0 in 35.0 seconds\n",
      "finished person 51 from fold #0 in 36.0 seconds\n",
      "finished person 52 from fold #0 in 35.0 seconds\n",
      "finished person 53 from fold #0 in 30.0 seconds\n",
      "finished person 54 from fold #0 in 37.0 seconds\n",
      "finished person 55 from fold #0 in 35.0 seconds\n",
      "finished person 56 from fold #0 in 36.0 seconds\n",
      "finished person 57 from fold #0 in 35.0 seconds\n",
      "finished person 58 from fold #0 in 35.0 seconds\n",
      "finished person 59 from fold #0 in 36.0 seconds\n",
      "finished person 60 from fold #0 in 35.0 seconds\n",
      "finished person 61 from fold #0 in 37.0 seconds\n",
      "finished person 62 from fold #0 in 37.0 seconds\n",
      "finished person 63 from fold #0 in 36.0 seconds\n",
      "finished person 64 from fold #0 in 35.0 seconds\n",
      "finished person 65 from fold #0 in 35.0 seconds\n",
      "finished person 66 from fold #0 in 35.0 seconds\n",
      "finished person 67 from fold #0 in 36.0 seconds\n",
      "finished person 68 from fold #0 in 36.0 seconds\n",
      "finished person 69 from fold #0 in 35.0 seconds\n",
      "finished person 70 from fold #0 in 36.0 seconds\n",
      "finished person 71 from fold #0 in 35.0 seconds\n",
      "finished person 72 from fold #0 in 35.0 seconds\n",
      "finished person 73 from fold #0 in 35.0 seconds\n",
      "finished person 74 from fold #0 in 36.0 seconds\n",
      "finished person 75 from fold #0 in 36.0 seconds\n",
      "finished person 76 from fold #0 in 35.0 seconds\n",
      "finished person 77 from fold #0 in 36.0 seconds\n",
      "finished person 78 from fold #0 in 36.0 seconds\n",
      "finished person 79 from fold #0 in 35.0 seconds\n",
      "finished person 80 from fold #0 in 35.0 seconds\n",
      "finished person 81 from fold #0 in 35.0 seconds\n",
      "finished person 82 from fold #0 in 34.0 seconds\n",
      "finished person 83 from fold #0 in 35.0 seconds\n",
      "finished person 84 from fold #0 in 36.0 seconds\n",
      "finished person 85 from fold #0 in 36.0 seconds\n",
      "finished person 86 from fold #0 in 35.0 seconds\n",
      "finished person 87 from fold #0 in 36.0 seconds\n",
      "finished person 88 from fold #0 in 35.0 seconds\n",
      "finished person 89 from fold #0 in 36.0 seconds\n",
      "finished person 90 from fold #0 in 35.0 seconds\n",
      "finished person 91 from fold #0 in 32.0 seconds\n",
      "finished person 92 from fold #0 in 35.0 seconds\n",
      "finished person 93 from fold #0 in 35.0 seconds\n",
      "finished person 94 from fold #0 in 35.0 seconds\n",
      "finished person 95 from fold #0 in 36.0 seconds\n",
      "finished person 96 from fold #0 in 36.0 seconds\n",
      "finished person 97 from fold #0 in 36.0 seconds\n",
      "finished person 98 from fold #0 in 34.0 seconds\n",
      "finished person 99 from fold #0 in 35.0 seconds\n",
      "finished person 100 from fold #0 in 36.0 seconds\n",
      "finished person 101 from fold #0 in 36.0 seconds\n",
      "finished person 102 from fold #0 in 34.0 seconds\n",
      "finished person 103 from fold #0 in 35.0 seconds\n",
      "finished person 104 from fold #0 in 35.0 seconds\n",
      "finished person 105 from fold #0 in 33.0 seconds\n",
      "finished person 106 from fold #0 in 33.0 seconds\n",
      "finished person 107 from fold #0 in 35.0 seconds\n",
      "finished person 108 from fold #0 in 36.0 seconds\n",
      "finished person 109 from fold #0 in 35.0 seconds\n",
      "finished person 110 from fold #0 in 35.0 seconds\n",
      "finished person 111 from fold #0 in 35.0 seconds\n",
      "finished person 112 from fold #0 in 36.0 seconds\n",
      "finished person 113 from fold #0 in 36.0 seconds\n",
      "finished person 114 from fold #0 in 36.0 seconds\n",
      "finished person 115 from fold #0 in 35.0 seconds\n",
      "finished person 116 from fold #0 in 35.0 seconds\n",
      "finished person 117 from fold #0 in 36.0 seconds\n",
      "finished person 118 from fold #0 in 34.0 seconds\n",
      "finished person 119 from fold #0 in 36.0 seconds\n",
      "finished person 120 from fold #0 in 36.0 seconds\n",
      "finished person 121 from fold #0 in 36.0 seconds\n",
      "finished person 122 from fold #0 in 36.0 seconds\n",
      "finished person 123 from fold #0 in 35.0 seconds\n",
      "finished person 124 from fold #0 in 34.0 seconds\n",
      "finished person 125 from fold #0 in 32.0 seconds\n",
      "finished person 126 from fold #0 in 35.0 seconds\n",
      "finished person 127 from fold #0 in 35.0 seconds\n",
      "finished person 128 from fold #0 in 35.0 seconds\n",
      "finished person 129 from fold #0 in 35.0 seconds\n",
      "finished person 130 from fold #0 in 35.0 seconds\n",
      "finished person 131 from fold #0 in 36.0 seconds\n",
      "finished person 132 from fold #0 in 36.0 seconds\n",
      "finished person 133 from fold #0 in 36.0 seconds\n",
      "finished person 134 from fold #0 in 35.0 seconds\n",
      "finished person 135 from fold #0 in 36.0 seconds\n",
      "finished person 136 from fold #0 in 36.0 seconds\n",
      "finished person 137 from fold #0 in 35.0 seconds\n",
      "finished person 138 from fold #0 in 35.0 seconds\n",
      "finished person 139 from fold #0 in 35.0 seconds\n",
      "finished person 140 from fold #0 in 36.0 seconds\n",
      "finished person 141 from fold #0 in 35.0 seconds\n",
      "finished person 142 from fold #0 in 36.0 seconds\n",
      "finished person 143 from fold #0 in 34.0 seconds\n",
      "finished person 144 from fold #0 in 36.0 seconds\n",
      "finished person 145 from fold #0 in 36.0 seconds\n",
      "finished person 146 from fold #0 in 36.0 seconds\n",
      "finished person 147 from fold #0 in 36.0 seconds\n",
      "finished person 148 from fold #0 in 35.0 seconds\n",
      "finished person 149 from fold #0 in 35.0 seconds\n",
      "finished person 150 from fold #0 in 34.0 seconds\n",
      "finished person 151 from fold #0 in 35.0 seconds\n",
      "finished person 152 from fold #0 in 30.0 seconds\n",
      "finished person 153 from fold #0 in 36.0 seconds\n",
      "finished person 154 from fold #0 in 36.0 seconds\n",
      "finished person 155 from fold #0 in 34.0 seconds\n",
      "finished person 156 from fold #0 in 36.0 seconds\n",
      "finished person 157 from fold #0 in 35.0 seconds\n",
      "finished person 158 from fold #0 in 35.0 seconds\n",
      "finished person 159 from fold #0 in 36.0 seconds\n",
      "finished person 160 from fold #0 in 36.0 seconds\n",
      "finished person 161 from fold #0 in 36.0 seconds\n",
      "finished person 162 from fold #0 in 35.0 seconds\n",
      "finished person 163 from fold #0 in 35.0 seconds\n",
      "finished person 164 from fold #0 in 34.0 seconds\n",
      "finished person 165 from fold #0 in 36.0 seconds\n",
      "finished person 166 from fold #0 in 35.0 seconds\n",
      "finished person 167 from fold #0 in 36.0 seconds\n",
      "finished person 168 from fold #0 in 35.0 seconds\n",
      "finished person 169 from fold #0 in 35.0 seconds\n",
      "finished person 170 from fold #0 in 31.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 171 from fold #0 in 35.0 seconds\n",
      "finished person 172 from fold #0 in 35.0 seconds\n",
      "finished person 173 from fold #0 in 35.0 seconds\n",
      "finished person 174 from fold #0 in 35.0 seconds\n",
      "finished person 175 from fold #0 in 36.0 seconds\n",
      "finished person 176 from fold #0 in 34.0 seconds\n",
      "finished person 177 from fold #0 in 36.0 seconds\n",
      "finished person 178 from fold #0 in 36.0 seconds\n",
      "finished person 179 from fold #0 in 35.0 seconds\n",
      "finished person 180 from fold #0 in 35.0 seconds\n",
      "finished person 181 from fold #0 in 36.0 seconds\n",
      "finished person 182 from fold #0 in 34.0 seconds\n",
      "finished person 183 from fold #0 in 36.0 seconds\n",
      "finished person 184 from fold #0 in 36.0 seconds\n",
      "finished person 185 from fold #0 in 34.0 seconds\n",
      "finished person 186 from fold #0 in 35.0 seconds\n",
      "finished person 187 from fold #0 in 34.0 seconds\n",
      "finished person 188 from fold #0 in 34.0 seconds\n",
      "finished person 189 from fold #0 in 35.0 seconds\n",
      "finished person 190 from fold #0 in 35.0 seconds\n",
      "finished person 191 from fold #0 in 36.0 seconds\n",
      "finished person 192 from fold #0 in 36.0 seconds\n",
      "finished person 193 from fold #0 in 35.0 seconds\n",
      "finished person 194 from fold #0 in 36.0 seconds\n",
      "finished person 1 from fold #1 in 35.0 seconds\n",
      "finished person 2 from fold #1 in 35.0 seconds\n",
      "finished person 3 from fold #1 in 34.0 seconds\n",
      "finished person 4 from fold #1 in 35.0 seconds\n",
      "finished person 5 from fold #1 in 36.0 seconds\n",
      "finished person 6 from fold #1 in 35.0 seconds\n",
      "finished person 7 from fold #1 in 35.0 seconds\n",
      "finished person 8 from fold #1 in 35.0 seconds\n",
      "finished person 9 from fold #1 in 35.0 seconds\n",
      "finished person 10 from fold #1 in 35.0 seconds\n",
      "finished person 11 from fold #1 in 36.0 seconds\n",
      "finished person 12 from fold #1 in 35.0 seconds\n",
      "finished person 13 from fold #1 in 37.0 seconds\n",
      "finished person 14 from fold #1 in 33.0 seconds\n",
      "finished person 15 from fold #1 in 36.0 seconds\n",
      "finished person 16 from fold #1 in 35.0 seconds\n",
      "finished person 17 from fold #1 in 35.0 seconds\n",
      "finished person 18 from fold #1 in 33.0 seconds\n",
      "finished person 19 from fold #1 in 35.0 seconds\n",
      "finished person 20 from fold #1 in 35.0 seconds\n",
      "finished person 21 from fold #1 in 35.0 seconds\n",
      "finished person 22 from fold #1 in 35.0 seconds\n",
      "finished person 23 from fold #1 in 32.0 seconds\n",
      "finished person 24 from fold #1 in 36.0 seconds\n",
      "finished person 25 from fold #1 in 36.0 seconds\n",
      "finished person 26 from fold #1 in 34.0 seconds\n",
      "finished person 27 from fold #1 in 36.0 seconds\n",
      "finished person 28 from fold #1 in 36.0 seconds\n",
      "finished person 29 from fold #1 in 34.0 seconds\n",
      "finished person 30 from fold #1 in 36.0 seconds\n",
      "finished person 31 from fold #1 in 35.0 seconds\n",
      "finished person 32 from fold #1 in 36.0 seconds\n",
      "finished person 33 from fold #1 in 36.0 seconds\n",
      "finished person 34 from fold #1 in 36.0 seconds\n",
      "finished person 35 from fold #1 in 34.0 seconds\n",
      "finished person 36 from fold #1 in 36.0 seconds\n",
      "finished person 37 from fold #1 in 33.0 seconds\n",
      "finished person 38 from fold #1 in 36.0 seconds\n",
      "finished person 39 from fold #1 in 36.0 seconds\n",
      "finished person 40 from fold #1 in 35.0 seconds\n",
      "finished person 41 from fold #1 in 35.0 seconds\n",
      "finished person 42 from fold #1 in 36.0 seconds\n",
      "finished person 43 from fold #1 in 36.0 seconds\n",
      "finished person 44 from fold #1 in 36.0 seconds\n",
      "finished person 45 from fold #1 in 35.0 seconds\n",
      "finished person 46 from fold #1 in 36.0 seconds\n",
      "finished person 47 from fold #1 in 36.0 seconds\n",
      "finished person 48 from fold #1 in 36.0 seconds\n",
      "finished person 49 from fold #1 in 36.0 seconds\n",
      "finished person 50 from fold #1 in 36.0 seconds\n",
      "finished person 51 from fold #1 in 35.0 seconds\n",
      "finished person 52 from fold #1 in 36.0 seconds\n",
      "finished person 53 from fold #1 in 36.0 seconds\n",
      "finished person 54 from fold #1 in 36.0 seconds\n",
      "finished person 55 from fold #1 in 34.0 seconds\n",
      "finished person 56 from fold #1 in 36.0 seconds\n",
      "finished person 57 from fold #1 in 35.0 seconds\n",
      "finished person 58 from fold #1 in 35.0 seconds\n",
      "finished person 59 from fold #1 in 36.0 seconds\n",
      "finished person 60 from fold #1 in 36.0 seconds\n",
      "finished person 61 from fold #1 in 35.0 seconds\n",
      "finished person 62 from fold #1 in 36.0 seconds\n",
      "finished person 63 from fold #1 in 36.0 seconds\n",
      "finished person 64 from fold #1 in 36.0 seconds\n",
      "finished person 65 from fold #1 in 35.0 seconds\n",
      "finished person 66 from fold #1 in 35.0 seconds\n",
      "finished person 67 from fold #1 in 36.0 seconds\n",
      "finished person 68 from fold #1 in 36.0 seconds\n",
      "finished person 69 from fold #1 in 36.0 seconds\n",
      "finished person 70 from fold #1 in 35.0 seconds\n",
      "finished person 71 from fold #1 in 36.0 seconds\n",
      "finished person 72 from fold #1 in 36.0 seconds\n",
      "finished person 73 from fold #1 in 36.0 seconds\n",
      "finished person 74 from fold #1 in 36.0 seconds\n",
      "finished person 75 from fold #1 in 36.0 seconds\n",
      "finished person 76 from fold #1 in 36.0 seconds\n",
      "finished person 77 from fold #1 in 36.0 seconds\n",
      "finished person 78 from fold #1 in 35.0 seconds\n",
      "finished person 79 from fold #1 in 35.0 seconds\n",
      "finished person 80 from fold #1 in 36.0 seconds\n",
      "finished person 81 from fold #1 in 36.0 seconds\n",
      "finished person 82 from fold #1 in 36.0 seconds\n",
      "finished person 83 from fold #1 in 36.0 seconds\n",
      "finished person 84 from fold #1 in 36.0 seconds\n",
      "finished person 85 from fold #1 in 36.0 seconds\n",
      "finished person 86 from fold #1 in 36.0 seconds\n",
      "finished person 87 from fold #1 in 36.0 seconds\n",
      "finished person 88 from fold #1 in 36.0 seconds\n",
      "finished person 89 from fold #1 in 36.0 seconds\n",
      "finished person 90 from fold #1 in 36.0 seconds\n",
      "finished person 91 from fold #1 in 35.0 seconds\n",
      "finished person 92 from fold #1 in 35.0 seconds\n",
      "finished person 93 from fold #1 in 36.0 seconds\n",
      "finished person 94 from fold #1 in 36.0 seconds\n",
      "finished person 95 from fold #1 in 36.0 seconds\n",
      "finished person 96 from fold #1 in 36.0 seconds\n",
      "finished person 97 from fold #1 in 36.0 seconds\n",
      "finished person 98 from fold #1 in 33.0 seconds\n",
      "finished person 99 from fold #1 in 35.0 seconds\n",
      "finished person 100 from fold #1 in 36.0 seconds\n",
      "finished person 101 from fold #1 in 36.0 seconds\n",
      "finished person 102 from fold #1 in 35.0 seconds\n",
      "finished person 103 from fold #1 in 33.0 seconds\n",
      "finished person 104 from fold #1 in 36.0 seconds\n",
      "finished person 105 from fold #1 in 32.0 seconds\n",
      "finished person 106 from fold #1 in 35.0 seconds\n",
      "finished person 107 from fold #1 in 36.0 seconds\n",
      "finished person 108 from fold #1 in 36.0 seconds\n",
      "finished person 109 from fold #1 in 35.0 seconds\n",
      "finished person 110 from fold #1 in 36.0 seconds\n",
      "finished person 111 from fold #1 in 36.0 seconds\n",
      "finished person 112 from fold #1 in 36.0 seconds\n",
      "finished person 113 from fold #1 in 35.0 seconds\n",
      "finished person 114 from fold #1 in 35.0 seconds\n",
      "finished person 115 from fold #1 in 36.0 seconds\n",
      "finished person 116 from fold #1 in 36.0 seconds\n",
      "finished person 117 from fold #1 in 36.0 seconds\n",
      "finished person 118 from fold #1 in 36.0 seconds\n",
      "finished person 119 from fold #1 in 36.0 seconds\n",
      "finished person 120 from fold #1 in 36.0 seconds\n",
      "finished person 121 from fold #1 in 36.0 seconds\n",
      "finished person 122 from fold #1 in 35.0 seconds\n",
      "finished person 123 from fold #1 in 36.0 seconds\n",
      "finished person 124 from fold #1 in 37.0 seconds\n",
      "finished person 125 from fold #1 in 36.0 seconds\n",
      "finished person 126 from fold #1 in 36.0 seconds\n",
      "finished person 127 from fold #1 in 36.0 seconds\n",
      "finished person 128 from fold #1 in 36.0 seconds\n",
      "finished person 129 from fold #1 in 36.0 seconds\n",
      "finished person 130 from fold #1 in 36.0 seconds\n",
      "finished person 131 from fold #1 in 36.0 seconds\n",
      "finished person 132 from fold #1 in 36.0 seconds\n",
      "finished person 133 from fold #1 in 36.0 seconds\n",
      "finished person 134 from fold #1 in 36.0 seconds\n",
      "finished person 135 from fold #1 in 36.0 seconds\n",
      "finished person 136 from fold #1 in 5.0 seconds\n",
      "finished person 137 from fold #1 in 35.0 seconds\n",
      "finished person 138 from fold #1 in 36.0 seconds\n",
      "finished person 139 from fold #1 in 35.0 seconds\n",
      "finished person 140 from fold #1 in 36.0 seconds\n",
      "finished person 141 from fold #1 in 36.0 seconds\n",
      "finished person 142 from fold #1 in 15.0 seconds\n",
      "finished person 143 from fold #1 in 36.0 seconds\n",
      "finished person 144 from fold #1 in 36.0 seconds\n",
      "finished person 145 from fold #1 in 35.0 seconds\n",
      "finished person 146 from fold #1 in 37.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 147 from fold #1 in 36.0 seconds\n",
      "finished person 148 from fold #1 in 36.0 seconds\n",
      "finished person 149 from fold #1 in 36.0 seconds\n",
      "finished person 150 from fold #1 in 36.0 seconds\n",
      "finished person 151 from fold #1 in 36.0 seconds\n",
      "finished person 152 from fold #1 in 36.0 seconds\n",
      "finished person 153 from fold #1 in 36.0 seconds\n",
      "finished person 154 from fold #1 in 37.0 seconds\n",
      "finished person 155 from fold #1 in 36.0 seconds\n",
      "finished person 156 from fold #1 in 38.0 seconds\n",
      "finished person 157 from fold #1 in 35.0 seconds\n",
      "finished person 158 from fold #1 in 36.0 seconds\n",
      "finished person 159 from fold #1 in 36.0 seconds\n",
      "finished person 160 from fold #1 in 35.0 seconds\n",
      "finished person 161 from fold #1 in 36.0 seconds\n",
      "finished person 162 from fold #1 in 36.0 seconds\n",
      "finished person 163 from fold #1 in 36.0 seconds\n",
      "finished person 164 from fold #1 in 36.0 seconds\n",
      "finished person 165 from fold #1 in 36.0 seconds\n",
      "finished person 166 from fold #1 in 36.0 seconds\n",
      "finished person 167 from fold #1 in 36.0 seconds\n",
      "finished person 168 from fold #1 in 35.0 seconds\n",
      "finished person 169 from fold #1 in 36.0 seconds\n",
      "finished person 170 from fold #1 in 36.0 seconds\n",
      "finished person 171 from fold #1 in 36.0 seconds\n",
      "finished person 172 from fold #1 in 36.0 seconds\n",
      "finished person 173 from fold #1 in 35.0 seconds\n",
      "finished person 174 from fold #1 in 36.0 seconds\n",
      "finished person 175 from fold #1 in 36.0 seconds\n",
      "finished person 176 from fold #1 in 36.0 seconds\n",
      "finished person 177 from fold #1 in 34.0 seconds\n",
      "finished person 178 from fold #1 in 35.0 seconds\n",
      "finished person 179 from fold #1 in 36.0 seconds\n",
      "finished person 180 from fold #1 in 35.0 seconds\n",
      "finished person 181 from fold #1 in 36.0 seconds\n",
      "finished person 182 from fold #1 in 36.0 seconds\n",
      "finished person 183 from fold #1 in 36.0 seconds\n",
      "finished person 184 from fold #1 in 36.0 seconds\n",
      "finished person 185 from fold #1 in 32.0 seconds\n",
      "finished person 186 from fold #1 in 36.0 seconds\n",
      "finished person 187 from fold #1 in 36.0 seconds\n",
      "finished person 188 from fold #1 in 34.0 seconds\n",
      "finished person 189 from fold #1 in 36.0 seconds\n",
      "finished person 190 from fold #1 in 35.0 seconds\n",
      "finished person 191 from fold #1 in 36.0 seconds\n",
      "finished person 192 from fold #1 in 36.0 seconds\n",
      "finished person 193 from fold #1 in 36.0 seconds\n",
      "finished person 194 from fold #1 in 36.0 seconds\n",
      "finished person 1 from fold #2 in 36.0 seconds\n",
      "finished person 2 from fold #2 in 36.0 seconds\n",
      "finished person 3 from fold #2 in 36.0 seconds\n",
      "finished person 4 from fold #2 in 36.0 seconds\n",
      "finished person 5 from fold #2 in 36.0 seconds\n",
      "finished person 6 from fold #2 in 36.0 seconds\n",
      "finished person 7 from fold #2 in 36.0 seconds\n",
      "finished person 8 from fold #2 in 36.0 seconds\n",
      "finished person 9 from fold #2 in 36.0 seconds\n",
      "finished person 10 from fold #2 in 36.0 seconds\n",
      "finished person 11 from fold #2 in 36.0 seconds\n",
      "finished person 12 from fold #2 in 36.0 seconds\n",
      "finished person 13 from fold #2 in 35.0 seconds\n",
      "finished person 14 from fold #2 in 35.0 seconds\n",
      "finished person 15 from fold #2 in 36.0 seconds\n",
      "finished person 16 from fold #2 in 36.0 seconds\n",
      "finished person 17 from fold #2 in 36.0 seconds\n",
      "finished person 18 from fold #2 in 36.0 seconds\n",
      "finished person 19 from fold #2 in 36.0 seconds\n",
      "finished person 20 from fold #2 in 35.0 seconds\n",
      "finished person 21 from fold #2 in 17.0 seconds\n",
      "finished person 22 from fold #2 in 36.0 seconds\n",
      "finished person 23 from fold #2 in 36.0 seconds\n",
      "finished person 24 from fold #2 in 36.0 seconds\n",
      "finished person 25 from fold #2 in 36.0 seconds\n",
      "finished person 26 from fold #2 in 35.0 seconds\n",
      "finished person 27 from fold #2 in 36.0 seconds\n",
      "finished person 28 from fold #2 in 36.0 seconds\n",
      "finished person 29 from fold #2 in 36.0 seconds\n",
      "finished person 30 from fold #2 in 36.0 seconds\n",
      "finished person 31 from fold #2 in 35.0 seconds\n",
      "finished person 32 from fold #2 in 36.0 seconds\n",
      "finished person 33 from fold #2 in 37.0 seconds\n",
      "finished person 34 from fold #2 in 36.0 seconds\n",
      "finished person 35 from fold #2 in 36.0 seconds\n",
      "finished person 36 from fold #2 in 36.0 seconds\n",
      "finished person 37 from fold #2 in 36.0 seconds\n",
      "finished person 38 from fold #2 in 36.0 seconds\n",
      "finished person 39 from fold #2 in 36.0 seconds\n",
      "finished person 40 from fold #2 in 36.0 seconds\n",
      "finished person 41 from fold #2 in 35.0 seconds\n",
      "finished person 42 from fold #2 in 36.0 seconds\n",
      "finished person 43 from fold #2 in 36.0 seconds\n",
      "finished person 44 from fold #2 in 36.0 seconds\n",
      "finished person 45 from fold #2 in 33.0 seconds\n",
      "finished person 46 from fold #2 in 34.0 seconds\n",
      "finished person 47 from fold #2 in 36.0 seconds\n",
      "finished person 48 from fold #2 in 36.0 seconds\n",
      "finished person 49 from fold #2 in 36.0 seconds\n",
      "finished person 50 from fold #2 in 36.0 seconds\n",
      "finished person 51 from fold #2 in 36.0 seconds\n",
      "finished person 52 from fold #2 in 21.0 seconds\n",
      "finished person 53 from fold #2 in 36.0 seconds\n",
      "finished person 54 from fold #2 in 36.0 seconds\n",
      "finished person 55 from fold #2 in 36.0 seconds\n",
      "finished person 56 from fold #2 in 5.0 seconds\n",
      "finished person 57 from fold #2 in 36.0 seconds\n",
      "finished person 58 from fold #2 in 36.0 seconds\n",
      "finished person 59 from fold #2 in 36.0 seconds\n",
      "finished person 60 from fold #2 in 36.0 seconds\n",
      "finished person 61 from fold #2 in 36.0 seconds\n",
      "finished person 62 from fold #2 in 36.0 seconds\n",
      "finished person 63 from fold #2 in 36.0 seconds\n",
      "finished person 64 from fold #2 in 35.0 seconds\n",
      "finished person 65 from fold #2 in 36.0 seconds\n",
      "finished person 66 from fold #2 in 33.0 seconds\n",
      "finished person 67 from fold #2 in 36.0 seconds\n",
      "finished person 68 from fold #2 in 36.0 seconds\n",
      "finished person 69 from fold #2 in 36.0 seconds\n",
      "finished person 70 from fold #2 in 36.0 seconds\n",
      "finished person 71 from fold #2 in 36.0 seconds\n",
      "finished person 72 from fold #2 in 36.0 seconds\n",
      "finished person 73 from fold #2 in 36.0 seconds\n",
      "finished person 74 from fold #2 in 36.0 seconds\n",
      "finished person 75 from fold #2 in 31.0 seconds\n",
      "finished person 76 from fold #2 in 36.0 seconds\n",
      "finished person 77 from fold #2 in 35.0 seconds\n",
      "finished person 78 from fold #2 in 35.0 seconds\n",
      "finished person 79 from fold #2 in 35.0 seconds\n",
      "finished person 80 from fold #2 in 34.0 seconds\n",
      "finished person 81 from fold #2 in 36.0 seconds\n",
      "finished person 82 from fold #2 in 35.0 seconds\n",
      "finished person 83 from fold #2 in 36.0 seconds\n",
      "finished person 84 from fold #2 in 37.0 seconds\n",
      "finished person 85 from fold #2 in 36.0 seconds\n",
      "finished person 86 from fold #2 in 36.0 seconds\n",
      "finished person 87 from fold #2 in 36.0 seconds\n",
      "finished person 88 from fold #2 in 36.0 seconds\n",
      "finished person 89 from fold #2 in 36.0 seconds\n",
      "finished person 90 from fold #2 in 36.0 seconds\n",
      "finished person 91 from fold #2 in 36.0 seconds\n",
      "finished person 92 from fold #2 in 36.0 seconds\n",
      "finished person 93 from fold #2 in 34.0 seconds\n",
      "finished person 94 from fold #2 in 34.0 seconds\n",
      "finished person 95 from fold #2 in 36.0 seconds\n",
      "finished person 96 from fold #2 in 36.0 seconds\n",
      "finished person 97 from fold #2 in 34.0 seconds\n",
      "finished person 98 from fold #2 in 36.0 seconds\n",
      "finished person 99 from fold #2 in 36.0 seconds\n",
      "finished person 100 from fold #2 in 35.0 seconds\n",
      "finished person 101 from fold #2 in 36.0 seconds\n",
      "finished person 102 from fold #2 in 36.0 seconds\n",
      "finished person 103 from fold #2 in 36.0 seconds\n",
      "finished person 104 from fold #2 in 36.0 seconds\n",
      "finished person 105 from fold #2 in 37.0 seconds\n",
      "finished person 106 from fold #2 in 36.0 seconds\n",
      "finished person 107 from fold #2 in 36.0 seconds\n",
      "finished person 108 from fold #2 in 36.0 seconds\n",
      "finished person 109 from fold #2 in 36.0 seconds\n",
      "finished person 110 from fold #2 in 36.0 seconds\n",
      "finished person 111 from fold #2 in 36.0 seconds\n",
      "finished person 112 from fold #2 in 36.0 seconds\n",
      "finished person 113 from fold #2 in 36.0 seconds\n",
      "finished person 114 from fold #2 in 37.0 seconds\n",
      "finished person 115 from fold #2 in 36.0 seconds\n",
      "finished person 116 from fold #2 in 34.0 seconds\n",
      "finished person 117 from fold #2 in 36.0 seconds\n",
      "finished person 118 from fold #2 in 34.0 seconds\n",
      "finished person 119 from fold #2 in 36.0 seconds\n",
      "finished person 120 from fold #2 in 36.0 seconds\n",
      "finished person 121 from fold #2 in 32.0 seconds\n",
      "finished person 122 from fold #2 in 36.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 123 from fold #2 in 36.0 seconds\n",
      "finished person 124 from fold #2 in 37.0 seconds\n",
      "finished person 125 from fold #2 in 36.0 seconds\n",
      "finished person 126 from fold #2 in 36.0 seconds\n",
      "finished person 127 from fold #2 in 37.0 seconds\n",
      "finished person 128 from fold #2 in 36.0 seconds\n",
      "finished person 129 from fold #2 in 35.0 seconds\n",
      "finished person 130 from fold #2 in 36.0 seconds\n",
      "finished person 131 from fold #2 in 36.0 seconds\n",
      "finished person 132 from fold #2 in 36.0 seconds\n",
      "finished person 133 from fold #2 in 36.0 seconds\n",
      "finished person 134 from fold #2 in 36.0 seconds\n",
      "finished person 135 from fold #2 in 36.0 seconds\n",
      "finished person 136 from fold #2 in 36.0 seconds\n",
      "finished person 137 from fold #2 in 36.0 seconds\n",
      "finished person 138 from fold #2 in 36.0 seconds\n",
      "finished person 139 from fold #2 in 36.0 seconds\n",
      "finished person 140 from fold #2 in 36.0 seconds\n",
      "finished person 141 from fold #2 in 36.0 seconds\n",
      "finished person 142 from fold #2 in 37.0 seconds\n",
      "finished person 143 from fold #2 in 36.0 seconds\n",
      "finished person 144 from fold #2 in 36.0 seconds\n",
      "finished person 145 from fold #2 in 36.0 seconds\n",
      "finished person 146 from fold #2 in 35.0 seconds\n",
      "finished person 147 from fold #2 in 36.0 seconds\n",
      "finished person 148 from fold #2 in 36.0 seconds\n",
      "finished person 149 from fold #2 in 37.0 seconds\n",
      "finished person 150 from fold #2 in 36.0 seconds\n",
      "finished person 151 from fold #2 in 36.0 seconds\n",
      "finished person 152 from fold #2 in 36.0 seconds\n",
      "finished person 153 from fold #2 in 36.0 seconds\n",
      "finished person 154 from fold #2 in 36.0 seconds\n",
      "finished person 155 from fold #2 in 36.0 seconds\n",
      "finished person 156 from fold #2 in 36.0 seconds\n",
      "finished person 157 from fold #2 in 36.0 seconds\n",
      "finished person 158 from fold #2 in 36.0 seconds\n",
      "finished person 159 from fold #2 in 36.0 seconds\n",
      "finished person 160 from fold #2 in 36.0 seconds\n",
      "finished person 161 from fold #2 in 36.0 seconds\n",
      "finished person 162 from fold #2 in 36.0 seconds\n",
      "finished person 163 from fold #2 in 36.0 seconds\n",
      "finished person 164 from fold #2 in 35.0 seconds\n",
      "finished person 165 from fold #2 in 36.0 seconds\n",
      "finished person 166 from fold #2 in 36.0 seconds\n",
      "finished person 167 from fold #2 in 35.0 seconds\n",
      "finished person 168 from fold #2 in 36.0 seconds\n",
      "finished person 169 from fold #2 in 36.0 seconds\n",
      "finished person 170 from fold #2 in 36.0 seconds\n",
      "finished person 171 from fold #2 in 34.0 seconds\n",
      "finished person 172 from fold #2 in 37.0 seconds\n",
      "finished person 173 from fold #2 in 35.0 seconds\n",
      "finished person 174 from fold #2 in 36.0 seconds\n",
      "finished person 175 from fold #2 in 36.0 seconds\n",
      "finished person 176 from fold #2 in 33.0 seconds\n",
      "finished person 177 from fold #2 in 35.0 seconds\n",
      "finished person 178 from fold #2 in 34.0 seconds\n",
      "finished person 179 from fold #2 in 36.0 seconds\n",
      "finished person 180 from fold #2 in 35.0 seconds\n",
      "finished person 181 from fold #2 in 36.0 seconds\n",
      "finished person 182 from fold #2 in 35.0 seconds\n",
      "finished person 183 from fold #2 in 36.0 seconds\n",
      "finished person 184 from fold #2 in 36.0 seconds\n",
      "finished person 185 from fold #2 in 36.0 seconds\n",
      "finished person 186 from fold #2 in 37.0 seconds\n",
      "finished person 187 from fold #2 in 37.0 seconds\n",
      "finished person 188 from fold #2 in 36.0 seconds\n",
      "finished person 189 from fold #2 in 36.0 seconds\n",
      "finished person 190 from fold #2 in 36.0 seconds\n",
      "finished person 191 from fold #2 in 36.0 seconds\n",
      "finished person 192 from fold #2 in 35.0 seconds\n",
      "finished person 193 from fold #2 in 36.0 seconds\n",
      "finished person 1 from fold #3 in 37.0 seconds\n",
      "finished person 2 from fold #3 in 36.0 seconds\n",
      "finished person 3 from fold #3 in 36.0 seconds\n",
      "finished person 4 from fold #3 in 35.0 seconds\n",
      "finished person 5 from fold #3 in 35.0 seconds\n",
      "finished person 6 from fold #3 in 32.0 seconds\n",
      "finished person 7 from fold #3 in 35.0 seconds\n",
      "finished person 8 from fold #3 in 36.0 seconds\n",
      "finished person 9 from fold #3 in 37.0 seconds\n",
      "finished person 10 from fold #3 in 36.0 seconds\n",
      "finished person 11 from fold #3 in 36.0 seconds\n",
      "finished person 12 from fold #3 in 35.0 seconds\n",
      "finished person 13 from fold #3 in 36.0 seconds\n",
      "finished person 14 from fold #3 in 32.0 seconds\n",
      "finished person 15 from fold #3 in 36.0 seconds\n",
      "finished person 16 from fold #3 in 33.0 seconds\n",
      "finished person 17 from fold #3 in 36.0 seconds\n",
      "finished person 18 from fold #3 in 36.0 seconds\n",
      "finished person 19 from fold #3 in 36.0 seconds\n",
      "finished person 20 from fold #3 in 36.0 seconds\n",
      "finished person 21 from fold #3 in 30.0 seconds\n",
      "finished person 22 from fold #3 in 36.0 seconds\n",
      "finished person 23 from fold #3 in 35.0 seconds\n",
      "finished person 24 from fold #3 in 34.0 seconds\n",
      "finished person 25 from fold #3 in 33.0 seconds\n",
      "finished person 26 from fold #3 in 36.0 seconds\n",
      "finished person 27 from fold #3 in 36.0 seconds\n",
      "finished person 28 from fold #3 in 34.0 seconds\n",
      "finished person 29 from fold #3 in 35.0 seconds\n",
      "finished person 30 from fold #3 in 36.0 seconds\n",
      "finished person 31 from fold #3 in 36.0 seconds\n",
      "finished person 32 from fold #3 in 35.0 seconds\n",
      "finished person 33 from fold #3 in 36.0 seconds\n",
      "finished person 34 from fold #3 in 35.0 seconds\n",
      "finished person 35 from fold #3 in 36.0 seconds\n",
      "finished person 36 from fold #3 in 35.0 seconds\n",
      "finished person 37 from fold #3 in 35.0 seconds\n",
      "finished person 38 from fold #3 in 33.0 seconds\n",
      "finished person 39 from fold #3 in 36.0 seconds\n",
      "finished person 40 from fold #3 in 36.0 seconds\n",
      "finished person 41 from fold #3 in 35.0 seconds\n",
      "finished person 42 from fold #3 in 32.0 seconds\n",
      "finished person 43 from fold #3 in 36.0 seconds\n",
      "finished person 44 from fold #3 in 36.0 seconds\n",
      "finished person 45 from fold #3 in 36.0 seconds\n",
      "finished person 46 from fold #3 in 37.0 seconds\n",
      "finished person 47 from fold #3 in 35.0 seconds\n",
      "finished person 48 from fold #3 in 36.0 seconds\n",
      "finished person 49 from fold #3 in 36.0 seconds\n",
      "finished person 50 from fold #3 in 36.0 seconds\n",
      "finished person 51 from fold #3 in 34.0 seconds\n",
      "finished person 52 from fold #3 in 37.0 seconds\n",
      "finished person 53 from fold #3 in 36.0 seconds\n",
      "finished person 54 from fold #3 in 36.0 seconds\n",
      "finished person 55 from fold #3 in 36.0 seconds\n",
      "finished person 56 from fold #3 in 34.0 seconds\n",
      "finished person 57 from fold #3 in 36.0 seconds\n",
      "finished person 58 from fold #3 in 34.0 seconds\n",
      "finished person 59 from fold #3 in 31.0 seconds\n",
      "finished person 60 from fold #3 in 3.0 seconds\n",
      "finished person 61 from fold #3 in 36.0 seconds\n",
      "finished person 62 from fold #3 in 36.0 seconds\n",
      "finished person 63 from fold #3 in 37.0 seconds\n",
      "finished person 64 from fold #3 in 36.0 seconds\n",
      "finished person 65 from fold #3 in 32.0 seconds\n",
      "finished person 66 from fold #3 in 35.0 seconds\n",
      "finished person 67 from fold #3 in 35.0 seconds\n",
      "finished person 68 from fold #3 in 13.0 seconds\n",
      "finished person 69 from fold #3 in 36.0 seconds\n",
      "finished person 70 from fold #3 in 36.0 seconds\n",
      "finished person 71 from fold #3 in 33.0 seconds\n",
      "finished person 72 from fold #3 in 35.0 seconds\n",
      "finished person 73 from fold #3 in 36.0 seconds\n",
      "finished person 74 from fold #3 in 36.0 seconds\n",
      "finished person 75 from fold #3 in 35.0 seconds\n",
      "finished person 76 from fold #3 in 35.0 seconds\n",
      "finished person 77 from fold #3 in 36.0 seconds\n",
      "finished person 78 from fold #3 in 36.0 seconds\n",
      "finished person 79 from fold #3 in 37.0 seconds\n",
      "finished person 80 from fold #3 in 36.0 seconds\n",
      "finished person 81 from fold #3 in 36.0 seconds\n",
      "finished person 82 from fold #3 in 36.0 seconds\n",
      "finished person 83 from fold #3 in 36.0 seconds\n",
      "finished person 84 from fold #3 in 37.0 seconds\n",
      "finished person 85 from fold #3 in 36.0 seconds\n",
      "finished person 86 from fold #3 in 34.0 seconds\n",
      "finished person 87 from fold #3 in 36.0 seconds\n",
      "finished person 88 from fold #3 in 37.0 seconds\n",
      "finished person 89 from fold #3 in 35.0 seconds\n",
      "finished person 90 from fold #3 in 36.0 seconds\n",
      "finished person 91 from fold #3 in 34.0 seconds\n",
      "finished person 92 from fold #3 in 36.0 seconds\n",
      "finished person 93 from fold #3 in 35.0 seconds\n",
      "finished person 94 from fold #3 in 37.0 seconds\n",
      "finished person 95 from fold #3 in 36.0 seconds\n",
      "finished person 96 from fold #3 in 36.0 seconds\n",
      "finished person 97 from fold #3 in 32.0 seconds\n",
      "finished person 98 from fold #3 in 29.0 seconds\n",
      "finished person 99 from fold #3 in 35.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 100 from fold #3 in 35.0 seconds\n",
      "finished person 101 from fold #3 in 34.0 seconds\n",
      "finished person 102 from fold #3 in 36.0 seconds\n",
      "finished person 103 from fold #3 in 37.0 seconds\n",
      "finished person 104 from fold #3 in 33.0 seconds\n",
      "finished person 105 from fold #3 in 36.0 seconds\n",
      "finished person 106 from fold #3 in 35.0 seconds\n",
      "finished person 107 from fold #3 in 36.0 seconds\n",
      "finished person 108 from fold #3 in 35.0 seconds\n",
      "finished person 109 from fold #3 in 23.0 seconds\n",
      "finished person 110 from fold #3 in 35.0 seconds\n",
      "finished person 111 from fold #3 in 36.0 seconds\n",
      "finished person 112 from fold #3 in 36.0 seconds\n",
      "finished person 113 from fold #3 in 36.0 seconds\n",
      "finished person 114 from fold #3 in 36.0 seconds\n",
      "finished person 115 from fold #3 in 36.0 seconds\n",
      "finished person 116 from fold #3 in 37.0 seconds\n",
      "finished person 117 from fold #3 in 36.0 seconds\n",
      "finished person 118 from fold #3 in 36.0 seconds\n",
      "finished person 119 from fold #3 in 37.0 seconds\n",
      "finished person 120 from fold #3 in 35.0 seconds\n",
      "finished person 121 from fold #3 in 37.0 seconds\n",
      "finished person 122 from fold #3 in 37.0 seconds\n",
      "finished person 123 from fold #3 in 36.0 seconds\n",
      "finished person 124 from fold #3 in 61.0 seconds\n",
      "finished person 125 from fold #3 in 54.0 seconds\n",
      "finished person 126 from fold #3 in 55.0 seconds\n",
      "finished person 127 from fold #3 in 35.0 seconds\n",
      "finished person 128 from fold #3 in 37.0 seconds\n",
      "finished person 129 from fold #3 in 36.0 seconds\n",
      "finished person 130 from fold #3 in 37.0 seconds\n",
      "finished person 131 from fold #3 in 37.0 seconds\n",
      "finished person 132 from fold #3 in 36.0 seconds\n",
      "finished person 133 from fold #3 in 41.0 seconds\n",
      "finished person 134 from fold #3 in 65.0 seconds\n",
      "finished person 135 from fold #3 in 59.0 seconds\n",
      "finished person 136 from fold #3 in 46.0 seconds\n",
      "finished person 137 from fold #3 in 37.0 seconds\n",
      "finished person 138 from fold #3 in 33.0 seconds\n",
      "finished person 139 from fold #3 in 36.0 seconds\n",
      "finished person 140 from fold #3 in 37.0 seconds\n",
      "finished person 141 from fold #3 in 37.0 seconds\n",
      "finished person 142 from fold #3 in 36.0 seconds\n",
      "finished person 143 from fold #3 in 37.0 seconds\n",
      "finished person 144 from fold #3 in 22.0 seconds\n",
      "finished person 145 from fold #3 in 37.0 seconds\n",
      "finished person 146 from fold #3 in 37.0 seconds\n",
      "finished person 147 from fold #3 in 37.0 seconds\n",
      "finished person 148 from fold #3 in 34.0 seconds\n",
      "finished person 149 from fold #3 in 36.0 seconds\n",
      "finished person 150 from fold #3 in 37.0 seconds\n",
      "finished person 151 from fold #3 in 37.0 seconds\n",
      "finished person 152 from fold #3 in 36.0 seconds\n",
      "finished person 153 from fold #3 in 37.0 seconds\n",
      "finished person 154 from fold #3 in 37.0 seconds\n",
      "finished person 155 from fold #3 in 37.0 seconds\n",
      "finished person 156 from fold #3 in 37.0 seconds\n",
      "finished person 157 from fold #3 in 36.0 seconds\n",
      "finished person 158 from fold #3 in 33.0 seconds\n",
      "finished person 159 from fold #3 in 37.0 seconds\n",
      "finished person 160 from fold #3 in 36.0 seconds\n",
      "finished person 161 from fold #3 in 37.0 seconds\n",
      "finished person 162 from fold #3 in 36.0 seconds\n",
      "finished person 163 from fold #3 in 34.0 seconds\n",
      "finished person 164 from fold #3 in 61.0 seconds\n",
      "finished person 165 from fold #3 in 55.0 seconds\n",
      "finished person 166 from fold #3 in 54.0 seconds\n",
      "finished person 167 from fold #3 in 35.0 seconds\n",
      "finished person 168 from fold #3 in 36.0 seconds\n",
      "finished person 169 from fold #3 in 13.0 seconds\n",
      "finished person 170 from fold #3 in 36.0 seconds\n",
      "finished person 171 from fold #3 in 37.0 seconds\n",
      "finished person 172 from fold #3 in 33.0 seconds\n",
      "finished person 173 from fold #3 in 36.0 seconds\n",
      "finished person 174 from fold #3 in 36.0 seconds\n",
      "finished person 175 from fold #3 in 36.0 seconds\n",
      "finished person 176 from fold #3 in 36.0 seconds\n",
      "finished person 177 from fold #3 in 52.0 seconds\n",
      "finished person 178 from fold #3 in 60.0 seconds\n",
      "finished person 179 from fold #3 in 57.0 seconds\n",
      "finished person 180 from fold #3 in 37.0 seconds\n",
      "finished person 181 from fold #3 in 36.0 seconds\n",
      "finished person 182 from fold #3 in 37.0 seconds\n",
      "finished person 183 from fold #3 in 34.0 seconds\n",
      "finished person 184 from fold #3 in 37.0 seconds\n",
      "finished person 185 from fold #3 in 36.0 seconds\n",
      "finished person 186 from fold #3 in 36.0 seconds\n",
      "finished person 187 from fold #3 in 37.0 seconds\n",
      "finished person 188 from fold #3 in 37.0 seconds\n",
      "finished person 189 from fold #3 in 36.0 seconds\n",
      "finished person 190 from fold #3 in 36.0 seconds\n",
      "finished person 191 from fold #3 in 31.0 seconds\n",
      "finished person 192 from fold #3 in 36.0 seconds\n",
      "finished person 193 from fold #3 in 36.0 seconds\n",
      "finished person 1 from fold #4 in 37.0 seconds\n",
      "finished person 2 from fold #4 in 37.0 seconds\n",
      "finished person 3 from fold #4 in 37.0 seconds\n",
      "finished person 4 from fold #4 in 37.0 seconds\n",
      "finished person 5 from fold #4 in 36.0 seconds\n",
      "finished person 6 from fold #4 in 33.0 seconds\n",
      "finished person 7 from fold #4 in 37.0 seconds\n",
      "finished person 8 from fold #4 in 37.0 seconds\n",
      "finished person 9 from fold #4 in 36.0 seconds\n",
      "finished person 10 from fold #4 in 37.0 seconds\n",
      "finished person 11 from fold #4 in 34.0 seconds\n",
      "finished person 12 from fold #4 in 36.0 seconds\n",
      "finished person 13 from fold #4 in 34.0 seconds\n",
      "finished person 14 from fold #4 in 35.0 seconds\n",
      "finished person 15 from fold #4 in 36.0 seconds\n",
      "finished person 16 from fold #4 in 36.0 seconds\n",
      "finished person 17 from fold #4 in 37.0 seconds\n",
      "finished person 18 from fold #4 in 31.0 seconds\n",
      "finished person 19 from fold #4 in 57.0 seconds\n",
      "finished person 20 from fold #4 in 60.0 seconds\n",
      "finished person 21 from fold #4 in 54.0 seconds\n",
      "finished person 22 from fold #4 in 18.0 seconds\n",
      "finished person 23 from fold #4 in 35.0 seconds\n",
      "finished person 24 from fold #4 in 37.0 seconds\n",
      "finished person 25 from fold #4 in 36.0 seconds\n",
      "finished person 26 from fold #4 in 37.0 seconds\n",
      "finished person 27 from fold #4 in 37.0 seconds\n",
      "finished person 28 from fold #4 in 36.0 seconds\n",
      "finished person 29 from fold #4 in 36.0 seconds\n",
      "finished person 30 from fold #4 in 36.0 seconds\n",
      "finished person 31 from fold #4 in 37.0 seconds\n",
      "finished person 32 from fold #4 in 36.0 seconds\n",
      "finished person 33 from fold #4 in 48.0 seconds\n",
      "finished person 34 from fold #4 in 65.0 seconds\n",
      "finished person 35 from fold #4 in 58.0 seconds\n",
      "finished person 36 from fold #4 in 34.0 seconds\n",
      "finished person 37 from fold #4 in 37.0 seconds\n",
      "finished person 38 from fold #4 in 36.0 seconds\n",
      "finished person 39 from fold #4 in 34.0 seconds\n",
      "finished person 40 from fold #4 in 36.0 seconds\n",
      "finished person 41 from fold #4 in 36.0 seconds\n",
      "finished person 42 from fold #4 in 37.0 seconds\n",
      "finished person 43 from fold #4 in 36.0 seconds\n",
      "finished person 44 from fold #4 in 37.0 seconds\n",
      "finished person 45 from fold #4 in 36.0 seconds\n",
      "finished person 46 from fold #4 in 37.0 seconds\n",
      "finished person 47 from fold #4 in 35.0 seconds\n",
      "finished person 48 from fold #4 in 36.0 seconds\n",
      "finished person 49 from fold #4 in 36.0 seconds\n",
      "finished person 50 from fold #4 in 36.0 seconds\n",
      "finished person 51 from fold #4 in 37.0 seconds\n",
      "finished person 52 from fold #4 in 37.0 seconds\n",
      "finished person 53 from fold #4 in 35.0 seconds\n",
      "finished person 54 from fold #4 in 31.0 seconds\n",
      "finished person 55 from fold #4 in 33.0 seconds\n",
      "finished person 56 from fold #4 in 30.0 seconds\n",
      "finished person 57 from fold #4 in 36.0 seconds\n",
      "finished person 58 from fold #4 in 36.0 seconds\n",
      "finished person 59 from fold #4 in 36.0 seconds\n",
      "finished person 60 from fold #4 in 31.0 seconds\n",
      "finished person 61 from fold #4 in 36.0 seconds\n",
      "finished person 62 from fold #4 in 36.0 seconds\n",
      "finished person 63 from fold #4 in 36.0 seconds\n",
      "finished person 64 from fold #4 in 37.0 seconds\n",
      "finished person 65 from fold #4 in 36.0 seconds\n",
      "finished person 66 from fold #4 in 37.0 seconds\n",
      "finished person 67 from fold #4 in 36.0 seconds\n",
      "finished person 68 from fold #4 in 36.0 seconds\n",
      "finished person 69 from fold #4 in 36.0 seconds\n",
      "finished person 70 from fold #4 in 36.0 seconds\n",
      "finished person 71 from fold #4 in 36.0 seconds\n",
      "finished person 72 from fold #4 in 59.0 seconds\n",
      "finished person 73 from fold #4 in 61.0 seconds\n",
      "finished person 74 from fold #4 in 53.0 seconds\n",
      "finished person 75 from fold #4 in 36.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished person 76 from fold #4 in 37.0 seconds\n",
      "finished person 77 from fold #4 in 63.0 seconds\n",
      "finished person 78 from fold #4 in 61.0 seconds\n",
      "finished person 79 from fold #4 in 52.0 seconds\n",
      "finished person 80 from fold #4 in 34.0 seconds\n",
      "finished person 81 from fold #4 in 35.0 seconds\n",
      "finished person 82 from fold #4 in 35.0 seconds\n",
      "finished person 83 from fold #4 in 36.0 seconds\n",
      "finished person 84 from fold #4 in 36.0 seconds\n",
      "finished person 85 from fold #4 in 36.0 seconds\n",
      "finished person 86 from fold #4 in 33.0 seconds\n",
      "finished person 87 from fold #4 in 33.0 seconds\n",
      "finished person 88 from fold #4 in 36.0 seconds\n",
      "finished person 89 from fold #4 in 37.0 seconds\n",
      "finished person 90 from fold #4 in 35.0 seconds\n",
      "finished person 91 from fold #4 in 36.0 seconds\n",
      "finished person 92 from fold #4 in 37.0 seconds\n",
      "finished person 93 from fold #4 in 37.0 seconds\n",
      "finished person 94 from fold #4 in 36.0 seconds\n",
      "finished person 95 from fold #4 in 37.0 seconds\n",
      "finished person 96 from fold #4 in 36.0 seconds\n",
      "finished person 97 from fold #4 in 36.0 seconds\n",
      "finished person 98 from fold #4 in 36.0 seconds\n",
      "finished person 99 from fold #4 in 36.0 seconds\n",
      "finished person 100 from fold #4 in 32.0 seconds\n",
      "finished person 101 from fold #4 in 27.0 seconds\n",
      "finished person 102 from fold #4 in 37.0 seconds\n",
      "finished person 103 from fold #4 in 36.0 seconds\n",
      "finished person 104 from fold #4 in 36.0 seconds\n",
      "finished person 105 from fold #4 in 36.0 seconds\n",
      "finished person 106 from fold #4 in 37.0 seconds\n",
      "finished person 107 from fold #4 in 37.0 seconds\n",
      "finished person 108 from fold #4 in 37.0 seconds\n",
      "finished person 109 from fold #4 in 37.0 seconds\n",
      "finished person 110 from fold #4 in 35.0 seconds\n",
      "finished person 111 from fold #4 in 36.0 seconds\n",
      "finished person 112 from fold #4 in 36.0 seconds\n",
      "finished person 113 from fold #4 in 36.0 seconds\n",
      "finished person 114 from fold #4 in 36.0 seconds\n",
      "finished person 115 from fold #4 in 34.0 seconds\n",
      "finished person 116 from fold #4 in 29.0 seconds\n",
      "finished person 117 from fold #4 in 34.0 seconds\n",
      "finished person 118 from fold #4 in 46.0 seconds\n",
      "finished person 119 from fold #4 in 62.0 seconds\n",
      "finished person 120 from fold #4 in 59.0 seconds\n",
      "finished person 121 from fold #4 in 40.0 seconds\n",
      "finished person 122 from fold #4 in 36.0 seconds\n",
      "finished person 123 from fold #4 in 23.0 seconds\n",
      "finished person 124 from fold #4 in 36.0 seconds\n",
      "finished person 125 from fold #4 in 37.0 seconds\n",
      "finished person 126 from fold #4 in 34.0 seconds\n",
      "finished person 127 from fold #4 in 60.0 seconds\n",
      "finished person 128 from fold #4 in 62.0 seconds\n",
      "finished person 129 from fold #4 in 55.0 seconds\n",
      "finished person 130 from fold #4 in 34.0 seconds\n",
      "finished person 131 from fold #4 in 37.0 seconds\n",
      "finished person 132 from fold #4 in 37.0 seconds\n",
      "finished person 133 from fold #4 in 36.0 seconds\n",
      "finished person 134 from fold #4 in 35.0 seconds\n",
      "finished person 135 from fold #4 in 37.0 seconds\n",
      "finished person 136 from fold #4 in 36.0 seconds\n",
      "finished person 137 from fold #4 in 36.0 seconds\n",
      "finished person 138 from fold #4 in 36.0 seconds\n",
      "finished person 139 from fold #4 in 36.0 seconds\n",
      "finished person 140 from fold #4 in 36.0 seconds\n",
      "finished person 141 from fold #4 in 33.0 seconds\n",
      "finished person 142 from fold #4 in 36.0 seconds\n",
      "finished person 143 from fold #4 in 36.0 seconds\n",
      "finished person 144 from fold #4 in 35.0 seconds\n",
      "finished person 145 from fold #4 in 36.0 seconds\n",
      "finished person 146 from fold #4 in 36.0 seconds\n",
      "finished person 147 from fold #4 in 35.0 seconds\n",
      "finished person 148 from fold #4 in 36.0 seconds\n",
      "finished person 149 from fold #4 in 37.0 seconds\n",
      "finished person 150 from fold #4 in 36.0 seconds\n",
      "finished person 151 from fold #4 in 36.0 seconds\n",
      "finished person 152 from fold #4 in 51.0 seconds\n",
      "finished person 153 from fold #4 in 41.0 seconds\n",
      "finished person 154 from fold #4 in 54.0 seconds\n",
      "finished person 155 from fold #4 in 43.0 seconds\n",
      "finished person 156 from fold #4 in 37.0 seconds\n",
      "finished person 157 from fold #4 in 28.0 seconds\n",
      "finished person 158 from fold #4 in 36.0 seconds\n",
      "finished person 159 from fold #4 in 36.0 seconds\n",
      "finished person 160 from fold #4 in 36.0 seconds\n",
      "finished person 161 from fold #4 in 36.0 seconds\n",
      "finished person 162 from fold #4 in 35.0 seconds\n",
      "finished person 163 from fold #4 in 36.0 seconds\n",
      "finished person 164 from fold #4 in 36.0 seconds\n",
      "finished person 165 from fold #4 in 36.0 seconds\n",
      "finished person 166 from fold #4 in 36.0 seconds\n",
      "finished person 167 from fold #4 in 36.0 seconds\n",
      "finished person 168 from fold #4 in 36.0 seconds\n",
      "finished person 169 from fold #4 in 36.0 seconds\n",
      "finished person 170 from fold #4 in 51.0 seconds\n",
      "finished person 171 from fold #4 in 63.0 seconds\n",
      "finished person 172 from fold #4 in 60.0 seconds\n",
      "finished person 173 from fold #4 in 37.0 seconds\n",
      "finished person 174 from fold #4 in 36.0 seconds\n",
      "finished person 175 from fold #4 in 36.0 seconds\n",
      "finished person 176 from fold #4 in 37.0 seconds\n",
      "finished person 177 from fold #4 in 34.0 seconds\n",
      "finished person 178 from fold #4 in 34.0 seconds\n",
      "finished person 179 from fold #4 in 36.0 seconds\n",
      "finished person 180 from fold #4 in 36.0 seconds\n",
      "finished person 181 from fold #4 in 36.0 seconds\n",
      "finished person 182 from fold #4 in 33.0 seconds\n",
      "finished person 183 from fold #4 in 37.0 seconds\n",
      "finished person 184 from fold #4 in 29.0 seconds\n",
      "finished person 185 from fold #4 in 36.0 seconds\n",
      "finished person 186 from fold #4 in 36.0 seconds\n",
      "finished person 187 from fold #4 in 37.0 seconds\n",
      "finished person 188 from fold #4 in 36.0 seconds\n",
      "finished person 189 from fold #4 in 34.0 seconds\n",
      "finished person 190 from fold #4 in 36.0 seconds\n",
      "finished person 191 from fold #4 in 37.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# flatten folds and run test\n",
    "folded_tests_sets = []\n",
    "folded_results = []\n",
    "counter = 0\n",
    "for path, cur_save_dir, test_2, test_3, test_4 in zip(saving_paths, saving_dirs, payoff2_test_participants_5fold_list, payoff3_test_participants_5fold_list, payoff4_test_participants_5fold_list):\n",
    "    fold_set = [*test_2 , *test_3 , *test_4]\n",
    "    folded_tests_sets.append(fold_set)\n",
    "    results = test_per_par(fold_set, counter, save_path=path)\n",
    "    folded_results.append(results)\n",
    "    counter+=1\n",
    "    with open(os.path.join(cur_save_dir, 'general_model_participants_test_results.pkl'), 'wb') as handle:\n",
    "        pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_model/corss_val/general_model/fold4/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## optional for when there's a need in last hidden state only\n",
    "# act_array = np.asarray(persons_activations)\n",
    "# last_hidden_states_per_person_per_time = []\n",
    "# for per in act_array:\n",
    "#     per_last_states = []\n",
    "#     for j in range(len(per)):\n",
    "#         if isinstance(per[j],int):\n",
    "#             per_last_states.append(-1)\n",
    "#         else:\n",
    "#             per_last_states.append(per[j][0][0][-1])\n",
    "#     last_hidden_states_per_person_per_time.append(per_last_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results = persons_true_false_predictions,persons_predictions_expr,total_actual_predictions,total_predicted_correct, persons_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_validation/general_model/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_model/corss_val/general_model/'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(saving_dir, 'general_model_results_5folds.pkl'), 'wb') as f:\n",
    "    pickle.dump(folded_results, f)\n",
    "\n",
    "# # old version : just the last state\n",
    "# with open(os.path.join(saving_dir, 'activations_tf_no_reward.pkl'), 'wb') as f:\n",
    "#     pickle.dump(last_hidden_states_per_person_per_time, f)\n",
    "\n",
    "    \n",
    "# with open(os.path.join(saving_dir, 'activations_FULL_tf_no_reward.pkl'), 'wb') as f:\n",
    "#     pickle.dump(persons_activations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
